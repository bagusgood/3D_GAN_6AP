{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Do1wur6ZthDouO_EYi-TOPNEl9p16b8Q",
      "authorship_tag": "ABX9TyNuve2+oeb9Smt5x3dN6qIO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "989998f04b9e46bcb9a0d40dc168a228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_40f1300d8fd446a0a4bd2b101e168efe",
            "max": 1,
            "min": 0.05,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.05,
            "style": "IPY_MODEL_5e87732d2dee4fa8825dadc9c47d9afe",
            "value": 0.25
          }
        },
        "40f1300d8fd446a0a4bd2b101e168efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e87732d2dee4fa8825dadc9c47d9afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "418abd4182fe424087f745cd487abb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55b9cea9969e48fbab640afdcf82a548"
            ],
            "layout": "IPY_MODEL_275a9ae335ce4496b7de5c96ee66474a"
          }
        },
        "55b9cea9969e48fbab640afdcf82a548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6caf5cf5c9bd41b8a32cced6aa5cd259",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 250,
            "style": "IPY_MODEL_058b1539e2694bd1976029f7c546d883",
            "value": 250
          }
        },
        "275a9ae335ce4496b7de5c96ee66474a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6caf5cf5c9bd41b8a32cced6aa5cd259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058b1539e2694bd1976029f7c546d883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "e2dd802e17fb488b8de330ea6ba58e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Generate missing data only",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_79a22b70ef0d4904915d5962baa38990",
            "style": "IPY_MODEL_7ee2927cc6f04023aeec43fd0c5ff844",
            "value": false
          }
        },
        "79a22b70ef0d4904915d5962baa38990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ee2927cc6f04023aeec43fd0c5ff844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b9e6e98332d46e29af0b6b98263d1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf4571e9c0b34b74ba484bef97e03f8c",
              "IPY_MODEL_a1bf85bda86b4e449a8df19e58dbdd5b",
              "IPY_MODEL_3f525fb0ca1d40a8b29a62483ad1ddce"
            ],
            "layout": "IPY_MODEL_883d51c0775b4c96961b18b7fa53fd75"
          }
        },
        "cf4571e9c0b34b74ba484bef97e03f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00543a55ce5d47ef85864ab9effe1827",
            "placeholder": "​",
            "style": "IPY_MODEL_a8aa352f5a8f479ea875c48e23be1643",
            "value": "100%"
          }
        },
        "a1bf85bda86b4e449a8df19e58dbdd5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44486b9c7e74ca5bb6357ef3b8a77df",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8d314eee8d84ab39d8496c9e369b5c0",
            "value": 50
          }
        },
        "3f525fb0ca1d40a8b29a62483ad1ddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d924a11783964d14b8ccd568646c56bc",
            "placeholder": "​",
            "style": "IPY_MODEL_63bcf5d567364aa796fd0d719cc749db",
            "value": " 50/50 [03:17&lt;00:00,  3.96s/it]"
          }
        },
        "883d51c0775b4c96961b18b7fa53fd75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00543a55ce5d47ef85864ab9effe1827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8aa352f5a8f479ea875c48e23be1643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b44486b9c7e74ca5bb6357ef3b8a77df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d314eee8d84ab39d8496c9e369b5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d924a11783964d14b8ccd568646c56bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63bcf5d567364aa796fd0d719cc749db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfd15ac3a5174c2e86b52fe102e7ed6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ea16f2d1f734cf8b601062408153dc8",
              "IPY_MODEL_4f90b61a9f094082af38a12b55bc4146",
              "IPY_MODEL_fa7f81deab7d45d0a9b4d020b105010a"
            ],
            "layout": "IPY_MODEL_ad1d92bb374b47bd93e633a79abf26dc"
          }
        },
        "6ea16f2d1f734cf8b601062408153dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f702b18c166469ba3e91d079f6c8b91",
            "placeholder": "​",
            "style": "IPY_MODEL_75006360f65a4acc90014ce055e39ea8",
            "value": "100%"
          }
        },
        "4f90b61a9f094082af38a12b55bc4146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a63469b5f4554ca2b204433e26950e56",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_397c5e6ad3f14e9c96cfd5b812c69b2c",
            "value": 50
          }
        },
        "fa7f81deab7d45d0a9b4d020b105010a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa0c051c0284058815218e60a1f3d0b",
            "placeholder": "​",
            "style": "IPY_MODEL_9b0f2a3ce656429093fd66051e62bfb8",
            "value": " 50/50 [17:11&lt;00:00, 20.28s/it]"
          }
        },
        "ad1d92bb374b47bd93e633a79abf26dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f702b18c166469ba3e91d079f6c8b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75006360f65a4acc90014ce055e39ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a63469b5f4554ca2b204433e26950e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397c5e6ad3f14e9c96cfd5b812c69b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aaa0c051c0284058815218e60a1f3d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b0f2a3ce656429093fd66051e62bfb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bagusgood/3D_GAN_6AP/blob/main/GAN7AP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BTrVchXvfqIX"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import BatchNormalization, LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.backend import clear_session\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm_notebook\n",
        "from tqdm import tqdm\n",
        "from numpy.random import seed\n",
        "import tensorflow as tf\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Parameters\n",
        "num_of_classes = 20\n",
        "data_shape = (6,1)\n",
        "\n",
        "#MLP Parameters\n",
        "times_to_run = 50 #Number of times to run MLP model\n",
        "mlp_epochs = 40\n",
        "valid_split = 0.20\n",
        "\n",
        "#GAN Parameters\n",
        "latent_dim = 100\n",
        "gan_epochs = 100\n",
        "\n",
        "#Random Seeds\n",
        "selection_seed = 150\n",
        "seed_multiplier = 1000"
      ],
      "metadata": {
        "id": "ovPF25bGfsF6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = pd.read_csv(\"drive/MyDrive/dataset7AP.csv\")\n",
        "dataset = pd.read_csv(\"drive/MyDrive/Data6APBaru.csv\")\n",
        "labels = dataset.Class.values\n",
        "labels = labels - 1 #Original label values are from 1 to 4\n",
        "features = dataset.drop(columns='Class').values"
      ],
      "metadata": {
        "id": "COSTqCv7fy_X"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_fea, X_test, tr_label, Y_test = train_test_split(features,\n",
        "                                                    labels,\n",
        "                                                    test_size=0.5,\n",
        "                                                    random_state= selection_seed,\n",
        "                                                    stratify=labels)"
      ],
      "metadata": {
        "id": "Nql3W8DUf7_H"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb1 = widgets.Checkbox(description=\"Generate missing data only\")\n",
        "slider1 = widgets.FloatSlider(value=0.1, min=0.05, max=1, step=0.05)\n",
        "slider2 = widgets.IntSlider(value=250, min=0, max=1000, step=250)\n",
        "vb = widgets.VBox(children = [slider2])\n",
        "def checkbox(button):\n",
        "    if button['new']:\n",
        "        vb.children = []\n",
        "        slider2.value = 250 - int(slider1.value*250)\n",
        "    else:\n",
        "        vb.children = [slider2]\n",
        "        experiment3 = False\n",
        "cb1.observe(checkbox, names='value')\n",
        "\n",
        "print(\"Percentage of Real Data:\")\n",
        "display(slider1)\n",
        "print(\"Number of datapoints GAN generates:\")\n",
        "display(vb)\n",
        "display(cb1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "989998f04b9e46bcb9a0d40dc168a228",
            "40f1300d8fd446a0a4bd2b101e168efe",
            "5e87732d2dee4fa8825dadc9c47d9afe",
            "418abd4182fe424087f745cd487abb35",
            "55b9cea9969e48fbab640afdcf82a548",
            "275a9ae335ce4496b7de5c96ee66474a",
            "6caf5cf5c9bd41b8a32cced6aa5cd259",
            "058b1539e2694bd1976029f7c546d883",
            "e2dd802e17fb488b8de330ea6ba58e5a",
            "79a22b70ef0d4904915d5962baa38990",
            "7ee2927cc6f04023aeec43fd0c5ff844"
          ]
        },
        "id": "hFkjsvKdisdF",
        "outputId": "a0c32013-2a7e-4eba-b6c5-204348196ae0"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of Real Data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FloatSlider(value=0.1, max=1.0, min=0.05, step=0.05)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "989998f04b9e46bcb9a0d40dc168a228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of datapoints GAN generates:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(IntSlider(value=250, max=1000, step=250),))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "418abd4182fe424087f745cd487abb35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Checkbox(value=False, description='Generate missing data only')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2dd802e17fb488b8de330ea6ba58e5a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fraction_of_data = slider1.value\n",
        "data_to_gen = slider2.value\n",
        "\n",
        "X_train = []\n",
        "Z_train = [] #This is the same as X_train, but it's used for training the GAN\n",
        "Y_train = []\n",
        "\n",
        "for idx in range(20):\n",
        "    number_filter = np.where(tr_label == idx)\n",
        "    X_filtered, Y_filtered = tr_fea[number_filter], tr_label[number_filter]\n",
        "\n",
        "    num_of_data = (int)(fraction_of_data*X_filtered.shape[0])\n",
        "    RandIndex = np.random.choice(X_filtered.shape[0],\n",
        "                                 num_of_data,\n",
        "                                 replace=False)\n",
        "    Z_train.append(X_filtered[RandIndex])\n",
        "    X_train.extend(X_filtered[RandIndex])\n",
        "    Y_train.extend(Y_filtered[RandIndex])\n",
        "\n",
        "X_train = np.asarray(X_train, dtype=np.float32)\n",
        "Y_train = np.asarray(Y_train, dtype=np.float32)\n",
        "\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "\n",
        "Y_train_encoded = to_categorical(Y_train)\n",
        "Y_test_encoded = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "reKyHp3AgBcM"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data must be standized using standard scaler before using the MLP.\n",
        "scaler = StandardScaler()\n",
        "X_train_transformed = scaler.fit_transform(X_train)\n",
        "X_test_transformed = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "B2aWdr25gEIB"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_test_loss =[]\n",
        "all_test_acc = []\n",
        "history = []\n",
        "\n",
        "for i in tqdm_notebook(range(times_to_run)):\n",
        "    seed(i*seed_multiplier)\n",
        "    tf.random.set_seed(i*seed_multiplier)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_shape=(6,), activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(20, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=Adam(0.0002, 0.5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history_temp = model.fit(X_train_transformed,\n",
        "                            Y_train_encoded,\n",
        "                            epochs=mlp_epochs,\n",
        "                            batch_size=64,\n",
        "                            validation_split=valid_split,\n",
        "                            verbose=0)\n",
        "    history.append(history_temp)\n",
        "    test_loss, test_acc = model.evaluate(X_test_transformed,\n",
        "                                         Y_test_encoded,\n",
        "                                         verbose=0)\n",
        "\n",
        "    print(\"#{} Test acc:\".format(i), test_acc)\n",
        "\n",
        "    all_test_acc.append(test_acc)\n",
        "    all_test_loss.append(test_loss)\n",
        "    del(model)\n",
        "    clear_session()\n",
        "\n",
        "def average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "avr = round(average(all_test_acc),3)\n",
        "print(\"AVERAGE TEST ACCURACY : \",avr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986,
          "referenced_widgets": [
            "7b9e6e98332d46e29af0b6b98263d1b9",
            "cf4571e9c0b34b74ba484bef97e03f8c",
            "a1bf85bda86b4e449a8df19e58dbdd5b",
            "3f525fb0ca1d40a8b29a62483ad1ddce",
            "883d51c0775b4c96961b18b7fa53fd75",
            "00543a55ce5d47ef85864ab9effe1827",
            "a8aa352f5a8f479ea875c48e23be1643",
            "b44486b9c7e74ca5bb6357ef3b8a77df",
            "c8d314eee8d84ab39d8496c9e369b5c0",
            "d924a11783964d14b8ccd568646c56bc",
            "63bcf5d567364aa796fd0d719cc749db"
          ]
        },
        "id": "CNTWRgoAgHaC",
        "outputId": "48a8d2d0-8e50-40ab-fe0e-e52154a329af"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-3192e2ed082d>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for i in tqdm_notebook(range(times_to_run)):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b9e6e98332d46e29af0b6b98263d1b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#0 Test acc: 0.5285714268684387\n",
            "#1 Test acc: 0.4399999976158142\n",
            "#2 Test acc: 0.25999999046325684\n",
            "#3 Test acc: 0.49142858386039734\n",
            "#4 Test acc: 0.4628571569919586\n",
            "#5 Test acc: 0.4514285624027252\n",
            "#6 Test acc: 0.5171428322792053\n",
            "#7 Test acc: 0.6342856884002686\n",
            "#8 Test acc: 0.677142858505249\n",
            "#9 Test acc: 0.508571445941925\n",
            "#10 Test acc: 0.48571428656578064\n",
            "#11 Test acc: 0.5114285945892334\n",
            "#12 Test acc: 0.48571428656578064\n",
            "#13 Test acc: 0.5542857050895691\n",
            "#14 Test acc: 0.4457142949104309\n",
            "#15 Test acc: 0.41999998688697815\n",
            "#16 Test acc: 0.5314285755157471\n",
            "#17 Test acc: 0.37142857909202576\n",
            "#18 Test acc: 0.39142856001853943\n",
            "#19 Test acc: 0.5628571510314941\n",
            "#20 Test acc: 0.4828571379184723\n",
            "#21 Test acc: 0.4399999976158142\n",
            "#22 Test acc: 0.47999998927116394\n",
            "#23 Test acc: 0.44857141375541687\n",
            "#24 Test acc: 0.4714285731315613\n",
            "#25 Test acc: 0.5771428346633911\n",
            "#26 Test acc: 0.46000000834465027\n",
            "#27 Test acc: 0.49714285135269165\n",
            "#28 Test acc: 0.488571435213089\n",
            "#29 Test acc: 0.5514285564422607\n",
            "#30 Test acc: 0.5\n",
            "#31 Test acc: 0.42571428418159485\n",
            "#32 Test acc: 0.545714259147644\n",
            "#33 Test acc: 0.6714285612106323\n",
            "#34 Test acc: 0.43714284896850586\n",
            "#35 Test acc: 0.334285706281662\n",
            "#36 Test acc: 0.28285714983940125\n",
            "#37 Test acc: 0.4571428596973419\n",
            "#38 Test acc: 0.4828571379184723\n",
            "#39 Test acc: 0.5257142782211304\n",
            "#40 Test acc: 0.4942857027053833\n",
            "#41 Test acc: 0.5114285945892334\n",
            "#42 Test acc: 0.5514285564422607\n",
            "#43 Test acc: 0.47999998927116394\n",
            "#44 Test acc: 0.5742856860160828\n",
            "#45 Test acc: 0.5028571486473083\n",
            "#46 Test acc: 0.4457142949104309\n",
            "#47 Test acc: 0.4028571546077728\n",
            "#48 Test acc: 0.6371428370475769\n",
            "#49 Test acc: 0.5942857265472412\n",
            "AVERAGE TEST ACCURACY :  0.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainacc = []\n",
        "trainloss = []\n",
        "valacc = []\n",
        "valloss = []\n",
        "for i in range (len(history)):\n",
        "    trainacc.append(history[i].history['accuracy'])\n",
        "    trainloss.append(history[i].history['loss'])\n",
        "    valacc.append(history[i].history['val_accuracy'])\n",
        "    valloss.append(history[i].history['val_loss'])\n",
        "\n",
        "acc = np.mean(trainacc, axis=0)\n",
        "val_acc = np.mean(valacc, axis=0)\n",
        "loss = np.mean(trainloss, axis=0)\n",
        "val_loss = np.mean(valloss, axis=0)\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy for {}%'.format(fraction_of_data*100))\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss for {}%'.format(fraction_of_data*100))\n",
        "plt.legend()\n",
        "plt.savefig(\"Train - {}%.png\".format(fraction_of_data*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "Jd5bFoCJgLEu",
        "outputId": "46dc92a8-357a-485b-9651-1b9f1c2a65dd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(np.prod(data_shape), activation='tanh'))\n",
        "    model.add(Reshape(data_shape))\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    gendata = model(noise)\n",
        "\n",
        "    return Model(noise, gendata)\n",
        "\n",
        "def build_discriminator():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=data_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    data = Input(shape=data_shape)\n",
        "    validity = model(data)\n",
        "\n",
        "    return Model(data, validity)\n",
        "\n",
        "def train(epochs, features, batch_size=128):\n",
        "\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "            idx = np.random.randint(0, features.shape[0], batch_size)\n",
        "            data = features[idx]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            gen_data = generator.predict(noise)\n",
        "\n",
        "            d_loss_real = discriminator.train_on_batch(data, valid)\n",
        "            d_loss_fake = discriminator.train_on_batch(gen_data, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "            # Print progress\n",
        "            if gan_epochs % 10 == 0:\n",
        "              print(f\"Epoch: {epoch}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")"
      ],
      "metadata": {
        "id": "8z4s-mYFgO9H"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_data = []\n",
        "\n",
        "for i in tqdm(range(num_of_classes)):\n",
        "    discriminator = build_discriminator()\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=Adam(0.0002, 0.5),\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "    generator = build_generator()\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    gendata = generator(noise)\n",
        "    discriminator.trainable = False\n",
        "    validity = discriminator(gendata)\n",
        "    combined = Model(noise, validity)\n",
        "    combined.compile(loss='binary_crossentropy',\n",
        "                    optimizer=Adam(0.0002, 0.5))\n",
        "\n",
        "    minimaxscaler = MinMaxScaler((-1,1))\n",
        "    Z_train_transformed = minimaxscaler.fit_transform(Z_train[i])\n",
        "    Z_train_transformed = np.expand_dims(Z_train_transformed, axis=2)\n",
        "\n",
        "    train(epochs=gan_epochs,\n",
        "          features=Z_train_transformed,\n",
        "          batch_size=64)\n",
        "\n",
        "    noise = np.random.normal(0, 1, (data_to_gen, latent_dim))\n",
        "    gen_data_temp = generator.predict(noise)\n",
        "    gen_data_temp = np.asarray(gen_data_temp, dtype=np.float32)\n",
        "    gen_data_temp = np.squeeze(gen_data_temp)\n",
        "    gen_data_temp = minimaxscaler.inverse_transform(gen_data_temp)\n",
        "\n",
        "    gen_data.append(gen_data_temp)\n",
        "\n",
        "    clear_session()\n",
        "    del(discriminator)\n",
        "    del(generator)\n",
        "    del(combined)\n",
        "\n",
        "gen_data = np.asarray(gen_data, dtype=np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfVqEgaugZK8",
        "outputId": "867888f9-8847-44a2-e8b8-cb6ad3479af3"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7013921141624451, Generator Loss: 0.6937581300735474\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6853605508804321, Generator Loss: 0.6871979832649231\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6713793873786926, Generator Loss: 0.6806621551513672\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6587671041488647, Generator Loss: 0.6769921779632568\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6479320228099823, Generator Loss: 0.6902902126312256\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6341500580310822, Generator Loss: 0.7041265964508057\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6111635565757751, Generator Loss: 0.6977641582489014\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6032922863960266, Generator Loss: 0.7087209224700928\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.5817293524742126, Generator Loss: 0.726981520652771\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.5913632214069366, Generator Loss: 0.7560014128684998\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.5863442867994308, Generator Loss: 0.7379742860794067\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.5679264515638351, Generator Loss: 0.7417426109313965\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.5664229393005371, Generator Loss: 0.7856693267822266\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.5594616383314133, Generator Loss: 0.7824782729148865\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.5329171866178513, Generator Loss: 0.8253042697906494\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.5408648252487183, Generator Loss: 0.8343110084533691\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.5078244507312775, Generator Loss: 0.8370853662490845\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.5330336391925812, Generator Loss: 0.8982264995574951\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.5121592283248901, Generator Loss: 0.9370195865631104\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.5204134583473206, Generator Loss: 0.9808186888694763\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.499507337808609, Generator Loss: 0.8820003271102905\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.4947754144668579, Generator Loss: 0.9360169172286987\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.513157457113266, Generator Loss: 0.9928810596466064\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.496695414185524, Generator Loss: 0.9773561954498291\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.5041413456201553, Generator Loss: 1.0386724472045898\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.5020212680101395, Generator Loss: 1.0103615522384644\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.5158405154943466, Generator Loss: 1.0379356145858765\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.4960336238145828, Generator Loss: 1.0805211067199707\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.46048831939697266, Generator Loss: 1.025743842124939\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.43201763927936554, Generator Loss: 1.0468214750289917\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.48709163069725037, Generator Loss: 1.1335984468460083\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.4455241560935974, Generator Loss: 1.124936580657959\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.4482729882001877, Generator Loss: 1.1986429691314697\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.4524610638618469, Generator Loss: 1.1928536891937256\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.43107905983924866, Generator Loss: 1.2099566459655762\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.4435757100582123, Generator Loss: 1.205967664718628\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.42634791135787964, Generator Loss: 1.2195978164672852\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.4552767276763916, Generator Loss: 1.2738723754882812\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.4315420091152191, Generator Loss: 1.3139463663101196\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.43791142106056213, Generator Loss: 1.2689141035079956\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.4288218766450882, Generator Loss: 1.2699291706085205\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.4477943480014801, Generator Loss: 1.3307220935821533\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.4034690707921982, Generator Loss: 1.3080182075500488\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.45926332473754883, Generator Loss: 1.3552803993225098\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.424018993973732, Generator Loss: 1.3093974590301514\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.39978113770484924, Generator Loss: 1.2789206504821777\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.43522128462791443, Generator Loss: 1.2764825820922852\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.3918299376964569, Generator Loss: 1.2996493577957153\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.42089030146598816, Generator Loss: 1.2980270385742188\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.41236135363578796, Generator Loss: 1.3773581981658936\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.4118137061595917, Generator Loss: 1.2809913158416748\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.4256929010152817, Generator Loss: 1.3426213264465332\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.4424290955066681, Generator Loss: 1.389378547668457\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.39656391739845276, Generator Loss: 1.3107945919036865\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.4031786769628525, Generator Loss: 1.3797483444213867\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.4285498261451721, Generator Loss: 1.4604536294937134\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.4167383015155792, Generator Loss: 1.3161697387695312\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.4321501851081848, Generator Loss: 1.3062878847122192\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.433701753616333, Generator Loss: 1.2366242408752441\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.40513625741004944, Generator Loss: 1.193942904472351\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.4274643063545227, Generator Loss: 1.3101317882537842\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.4307449758052826, Generator Loss: 1.2500953674316406\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.43890537321567535, Generator Loss: 1.0940182209014893\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.3860226273536682, Generator Loss: 1.2536087036132812\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.4412611722946167, Generator Loss: 1.2961196899414062\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.4463227689266205, Generator Loss: 1.2785674333572388\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.43826019763946533, Generator Loss: 1.2472362518310547\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.4404335021972656, Generator Loss: 1.1702191829681396\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.4434463828802109, Generator Loss: 1.169815182685852\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.45958247780799866, Generator Loss: 1.1957073211669922\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.4597993940114975, Generator Loss: 1.0668230056762695\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.4577558934688568, Generator Loss: 1.1479763984680176\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.4612991213798523, Generator Loss: 1.2256674766540527\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.42484256625175476, Generator Loss: 1.1237504482269287\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.4276174306869507, Generator Loss: 1.2213680744171143\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.4278445988893509, Generator Loss: 1.2265565395355225\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.43267083168029785, Generator Loss: 1.2620675563812256\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.478122740983963, Generator Loss: 1.1192538738250732\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.4241143763065338, Generator Loss: 1.0619571208953857\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.4763931334018707, Generator Loss: 1.1753613948822021\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.49654896557331085, Generator Loss: 1.01646089553833\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.45631805062294006, Generator Loss: 1.1230924129486084\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.4109519422054291, Generator Loss: 1.123591661453247\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.4741801768541336, Generator Loss: 1.053310751914978\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.46065452694892883, Generator Loss: 1.0111591815948486\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5110364258289337, Generator Loss: 1.1191473007202148\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.4702652394771576, Generator Loss: 1.11370050907135\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.48136553168296814, Generator Loss: 1.0637331008911133\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.49570587277412415, Generator Loss: 1.200578212738037\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.491587370634079, Generator Loss: 1.091856837272644\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.45194748044013977, Generator Loss: 1.1373364925384521\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.45850709080696106, Generator Loss: 1.2233929634094238\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.49069198966026306, Generator Loss: 1.1899266242980957\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.454516664147377, Generator Loss: 0.9912315011024475\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.45841386914253235, Generator Loss: 1.1254026889801025\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.4380649924278259, Generator Loss: 1.1607294082641602\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.4409912973642349, Generator Loss: 1.1359080076217651\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.4512488842010498, Generator Loss: 1.171422004699707\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.4677063524723053, Generator Loss: 0.9944509267807007\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.4624965786933899, Generator Loss: 1.1635611057281494\n",
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [00:19<06:16, 19.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7164722383022308, Generator Loss: 0.697150707244873\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6946455538272858, Generator Loss: 0.6893452405929565\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6774675250053406, Generator Loss: 0.6909727454185486\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6609160006046295, Generator Loss: 0.6909369230270386\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6435713171958923, Generator Loss: 0.6890887022018433\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6292462348937988, Generator Loss: 0.6860383749008179\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6167588531970978, Generator Loss: 0.7025223970413208\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.599716067314148, Generator Loss: 0.7089412212371826\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.5792738795280457, Generator Loss: 0.722083568572998\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.5621176362037659, Generator Loss: 0.7395848631858826\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.5500927567481995, Generator Loss: 0.7499048113822937\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.540449246764183, Generator Loss: 0.7260065674781799\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.5515243709087372, Generator Loss: 0.7627325654029846\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.5499225556850433, Generator Loss: 0.7686449289321899\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.5213964134454727, Generator Loss: 0.7923496961593628\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.5161772668361664, Generator Loss: 0.8349072933197021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.48742222785949707, Generator Loss: 0.8206867575645447\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.5016407072544098, Generator Loss: 0.8528907299041748\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.5172588378190994, Generator Loss: 0.8677470684051514\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.4959193021059036, Generator Loss: 0.8872897624969482\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.5106119513511658, Generator Loss: 0.918979287147522\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.49054233729839325, Generator Loss: 0.941493570804596\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.5374387949705124, Generator Loss: 0.9471891522407532\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.47475486993789673, Generator Loss: 0.9886547327041626\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.4657783806324005, Generator Loss: 0.9448255896568298\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.43565332889556885, Generator Loss: 1.023552417755127\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.46360310912132263, Generator Loss: 0.9708201885223389\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.4844811409711838, Generator Loss: 1.0082802772521973\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.4362691342830658, Generator Loss: 1.0215766429901123\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.48452508449554443, Generator Loss: 1.0513851642608643\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.4442661702632904, Generator Loss: 1.1312787532806396\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.4644795209169388, Generator Loss: 1.100098967552185\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.45218509435653687, Generator Loss: 1.0890328884124756\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.5011475384235382, Generator Loss: 1.1794068813323975\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.47597500681877136, Generator Loss: 1.070336103439331\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.4758664220571518, Generator Loss: 1.1082355976104736\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.4659763276576996, Generator Loss: 1.1234650611877441\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.45177873969078064, Generator Loss: 1.1061583757400513\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.504040539264679, Generator Loss: 1.1168930530548096\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.45084603130817413, Generator Loss: 1.1964826583862305\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.4373100996017456, Generator Loss: 1.1648356914520264\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.443441778421402, Generator Loss: 1.1191380023956299\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.4332893192768097, Generator Loss: 1.2137579917907715\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.41840803623199463, Generator Loss: 1.2164437770843506\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.47253745794296265, Generator Loss: 1.2387919425964355\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.4580058306455612, Generator Loss: 1.249671220779419\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.4458463042974472, Generator Loss: 1.2161951065063477\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.4429965317249298, Generator Loss: 1.1976702213287354\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.44630685448646545, Generator Loss: 1.3308539390563965\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.4077546000480652, Generator Loss: 1.2473087310791016\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.46429744362831116, Generator Loss: 1.2174299955368042\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.3806922286748886, Generator Loss: 1.1829397678375244\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.4509047269821167, Generator Loss: 1.2771012783050537\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.45271795988082886, Generator Loss: 1.2474907636642456\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5224241316318512, Generator Loss: 1.2131247520446777\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.4142274558544159, Generator Loss: 1.2058216333389282\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.3931414932012558, Generator Loss: 1.2391226291656494\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.4718082547187805, Generator Loss: 1.2713004350662231\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.4472392350435257, Generator Loss: 1.0767923593521118\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.48906657099723816, Generator Loss: 1.2200520038604736\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.4324401021003723, Generator Loss: 1.3344085216522217\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.44621607661247253, Generator Loss: 1.1681277751922607\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.4627043902873993, Generator Loss: 1.185697078704834\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.43345990777015686, Generator Loss: 1.2830700874328613\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.4738045483827591, Generator Loss: 1.067034363746643\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.4458450675010681, Generator Loss: 1.17335844039917\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.46354159712791443, Generator Loss: 1.1173081398010254\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.4756040573120117, Generator Loss: 1.132127046585083\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.46207568049430847, Generator Loss: 1.0543460845947266\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.44456541538238525, Generator Loss: 1.098309874534607\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.43811605870723724, Generator Loss: 1.1395938396453857\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.43984130024909973, Generator Loss: 1.1230263710021973\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.45986196398735046, Generator Loss: 1.173998236656189\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.46581655740737915, Generator Loss: 1.1772589683532715\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.4728287309408188, Generator Loss: 1.105176568031311\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.4847758561372757, Generator Loss: 1.2051119804382324\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.49229297041893005, Generator Loss: 1.2891789674758911\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5102091729640961, Generator Loss: 1.129225730895996\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.513896107673645, Generator Loss: 1.1324857473373413\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5066225975751877, Generator Loss: 1.1429320573806763\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.495199590921402, Generator Loss: 0.9751135110855103\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.4806174337863922, Generator Loss: 1.1428208351135254\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.47509902715682983, Generator Loss: 1.0557843446731567\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.47216349840164185, Generator Loss: 1.096704363822937\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5103894770145416, Generator Loss: 1.0431526899337769\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.46799609065055847, Generator Loss: 1.144840955734253\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5049654096364975, Generator Loss: 0.9721377491950989\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.47856083512306213, Generator Loss: 0.9063453674316406\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.524540588259697, Generator Loss: 0.9938933849334717\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.47788721323013306, Generator Loss: 0.9604483842849731\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.533495768904686, Generator Loss: 1.0719845294952393\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.46801823377609253, Generator Loss: 0.9801554679870605\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5381535291671753, Generator Loss: 0.9686943292617798\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5086687803268433, Generator Loss: 1.0480923652648926\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5054689645767212, Generator Loss: 0.9895371198654175\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5263264775276184, Generator Loss: 1.019090175628662\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5474285781383514, Generator Loss: 0.9777349233627319\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.547602504491806, Generator Loss: 1.0310791730880737\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5355822443962097, Generator Loss: 1.0184531211853027\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5038530975580215, Generator Loss: 1.0353045463562012\n",
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:48<07:28, 24.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.6876863241195679, Generator Loss: 0.6873655319213867\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6696987748146057, Generator Loss: 0.6791338324546814\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6579096913337708, Generator Loss: 0.6750878095626831\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6530351638793945, Generator Loss: 0.6613839864730835\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.644430547952652, Generator Loss: 0.6540893912315369\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6437366008758545, Generator Loss: 0.6440277099609375\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6408864259719849, Generator Loss: 0.6381458044052124\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6378963589668274, Generator Loss: 0.6522570848464966\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6437092125415802, Generator Loss: 0.6424148082733154\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6271149218082428, Generator Loss: 0.637302577495575\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6347263157367706, Generator Loss: 0.6420799493789673\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6428474932909012, Generator Loss: 0.6327430009841919\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.635982483625412, Generator Loss: 0.612576961517334\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6299230456352234, Generator Loss: 0.6614068746566772\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6231582313776016, Generator Loss: 0.639840304851532\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6382180601358414, Generator Loss: 0.6809816360473633\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.630942165851593, Generator Loss: 0.6739142537117004\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6173454821109772, Generator Loss: 0.6982142925262451\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6325053870677948, Generator Loss: 0.6989452838897705\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.6029290705919266, Generator Loss: 0.7206020355224609\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6259451508522034, Generator Loss: 0.7516905665397644\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.590399295091629, Generator Loss: 0.7293167114257812\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.5886134952306747, Generator Loss: 0.7395061254501343\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.5734410583972931, Generator Loss: 0.744608998298645\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.5852237939834595, Generator Loss: 0.7391066551208496\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.5546648800373077, Generator Loss: 0.7811161875724792\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.5541763603687286, Generator Loss: 0.7907178401947021\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5818917155265808, Generator Loss: 0.8046442866325378\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.5500478595495224, Generator Loss: 0.8139800429344177\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.5485486090183258, Generator Loss: 0.8494805097579956\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.5667915642261505, Generator Loss: 0.8006798624992371\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.5672397613525391, Generator Loss: 0.8324790596961975\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5325644612312317, Generator Loss: 0.8662393689155579\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.53921277821064, Generator Loss: 0.8362245559692383\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.5182993561029434, Generator Loss: 0.836184024810791\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.583843007683754, Generator Loss: 0.8422304391860962\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.5345025509595871, Generator Loss: 0.8905365467071533\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5544516444206238, Generator Loss: 0.902910590171814\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5758641958236694, Generator Loss: 0.8755882382392883\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.5447793453931808, Generator Loss: 0.8762729167938232\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5632357001304626, Generator Loss: 0.8754756450653076\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.5115451663732529, Generator Loss: 0.9542142152786255\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.4865610599517822, Generator Loss: 0.8681620359420776\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.5334761142730713, Generator Loss: 0.9781562089920044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.5577704310417175, Generator Loss: 0.8968945741653442\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.49879834055900574, Generator Loss: 0.976695716381073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.5286815762519836, Generator Loss: 0.9414263367652893\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5124135464429855, Generator Loss: 0.8612967729568481\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5325969457626343, Generator Loss: 0.8634053468704224\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5324050486087799, Generator Loss: 1.0154544115066528\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.49293550848960876, Generator Loss: 0.9615463018417358\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.557966411113739, Generator Loss: 0.8623886108398438\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.48218435049057007, Generator Loss: 0.9930331707000732\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5293688774108887, Generator Loss: 0.9183467626571655\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.540704146027565, Generator Loss: 0.9489740133285522\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.5648640990257263, Generator Loss: 0.9342378377914429\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.5370722711086273, Generator Loss: 0.963347315788269\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.5311241447925568, Generator Loss: 0.9619150161743164\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5102736055850983, Generator Loss: 0.99241703748703\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5480592548847198, Generator Loss: 0.9402109980583191\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5491702854633331, Generator Loss: 0.9852635860443115\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5643020123243332, Generator Loss: 1.0106450319290161\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.5494626760482788, Generator Loss: 1.009313941001892\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.5144838690757751, Generator Loss: 0.9933840036392212\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5086069703102112, Generator Loss: 0.9755585789680481\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.5008763819932938, Generator Loss: 0.9211294651031494\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.5413310676813126, Generator Loss: 0.9348804950714111\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5412026047706604, Generator Loss: 0.902061939239502\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5069381594657898, Generator Loss: 0.980124831199646\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.5413624346256256, Generator Loss: 0.9691067337989807\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.5628374069929123, Generator Loss: 0.9535300731658936\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5668683648109436, Generator Loss: 0.9646915197372437\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5815329849720001, Generator Loss: 1.056918740272522\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5686976909637451, Generator Loss: 0.9580439329147339\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5806602835655212, Generator Loss: 0.9663772583007812\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5541002452373505, Generator Loss: 0.8935835361480713\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5713964104652405, Generator Loss: 0.9686082005500793\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5892218947410583, Generator Loss: 0.9920834898948669\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.554943323135376, Generator Loss: 0.8699581623077393\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5288459658622742, Generator Loss: 0.9662126302719116\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5716361254453659, Generator Loss: 0.9363546967506409\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5748476684093475, Generator Loss: 0.9118645191192627\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5783312916755676, Generator Loss: 0.9714046120643616\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5849614143371582, Generator Loss: 0.8428163528442383\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5936334431171417, Generator Loss: 0.8801729083061218\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5322968512773514, Generator Loss: 0.9164807200431824\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.6062495112419128, Generator Loss: 0.8411881923675537\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5734516382217407, Generator Loss: 0.9004629254341125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.6128913015127182, Generator Loss: 0.9972345232963562\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.562546581029892, Generator Loss: 0.9040745496749878\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5761330276727676, Generator Loss: 0.8985121250152588\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.5726828873157501, Generator Loss: 0.8470513820648193\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5859440565109253, Generator Loss: 0.9636094570159912\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.6129133701324463, Generator Loss: 0.8459967374801636\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5294592082500458, Generator Loss: 0.9247052669525146\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5565773546695709, Generator Loss: 0.9343823194503784\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5962851941585541, Generator Loss: 0.8075466156005859\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.6074782311916351, Generator Loss: 0.8513681888580322\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5906782150268555, Generator Loss: 0.8234018087387085\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5877214670181274, Generator Loss: 0.8649125099182129\n",
            "8/8 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [01:09<06:33, 23.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.6716416478157043, Generator Loss: 0.6439117193222046\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6569665372371674, Generator Loss: 0.6315139532089233\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6531171798706055, Generator Loss: 0.621475100517273\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6437768936157227, Generator Loss: 0.6187079548835754\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6391155123710632, Generator Loss: 0.6196482181549072\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6375916600227356, Generator Loss: 0.6193279027938843\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6278630793094635, Generator Loss: 0.6075418591499329\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6432778835296631, Generator Loss: 0.6148780584335327\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6336113810539246, Generator Loss: 0.6071741580963135\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6360995173454285, Generator Loss: 0.6287236213684082\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6393072605133057, Generator Loss: 0.624728798866272\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6309316456317902, Generator Loss: 0.6296629309654236\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6345261037349701, Generator Loss: 0.6403613686561584\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6492518484592438, Generator Loss: 0.66093909740448\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6236393749713898, Generator Loss: 0.6391507387161255\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6256804168224335, Generator Loss: 0.6688292622566223\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.6252228915691376, Generator Loss: 0.6892008185386658\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6165589988231659, Generator Loss: 0.7019063234329224\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6081975400447845, Generator Loss: 0.704203188419342\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.6218307912349701, Generator Loss: 0.7274117469787598\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6080380231142044, Generator Loss: 0.7029749155044556\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.6063880324363708, Generator Loss: 0.7386478185653687\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.5874226987361908, Generator Loss: 0.7213806509971619\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.6129631996154785, Generator Loss: 0.743584930896759\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.6038137078285217, Generator Loss: 0.7466060519218445\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.6011943519115448, Generator Loss: 0.7720462083816528\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.5771293640136719, Generator Loss: 0.7743635177612305\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5810627937316895, Generator Loss: 0.7896354794502258\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.5636314749717712, Generator Loss: 0.8129339218139648\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.5930559635162354, Generator Loss: 0.8329676389694214\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.5982936918735504, Generator Loss: 0.8408129811286926\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.5629707872867584, Generator Loss: 0.8344235420227051\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5729458928108215, Generator Loss: 0.7927459478378296\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.5596049726009369, Generator Loss: 0.8149145841598511\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.5634558796882629, Generator Loss: 0.8390549421310425\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5807951986789703, Generator Loss: 0.8639546632766724\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.5633704662322998, Generator Loss: 0.8903802633285522\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5304039716720581, Generator Loss: 0.8907631635665894\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5544762909412384, Generator Loss: 0.8276681900024414\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.543407142162323, Generator Loss: 0.9002538919448853\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.567025676369667, Generator Loss: 0.8444669246673584\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.5547165125608444, Generator Loss: 0.8862178921699524\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5750628411769867, Generator Loss: 0.8807054758071899\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.5215508937835693, Generator Loss: 0.9054166078567505\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.5484523922204971, Generator Loss: 0.9160913228988647\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.5241042524576187, Generator Loss: 0.865867018699646\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.5385885089635849, Generator Loss: 0.8928828239440918\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5462629050016403, Generator Loss: 0.9334010481834412\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5444159507751465, Generator Loss: 0.8869796991348267\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5575010478496552, Generator Loss: 0.9248193502426147\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5241550952196121, Generator Loss: 1.0584814548492432\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.567705899477005, Generator Loss: 0.9431289434432983\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.5140047818422318, Generator Loss: 0.9598425030708313\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5509475469589233, Generator Loss: 1.0286011695861816\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5297136902809143, Generator Loss: 0.9328030347824097\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.5543200671672821, Generator Loss: 0.8947429656982422\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.525003045797348, Generator Loss: 1.019507884979248\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.5769842863082886, Generator Loss: 0.9170939922332764\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5058526396751404, Generator Loss: 0.8932703733444214\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5138147324323654, Generator Loss: 1.0204263925552368\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5285471975803375, Generator Loss: 0.9834628105163574\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5551532953977585, Generator Loss: 1.0250624418258667\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.5411050617694855, Generator Loss: 0.9609183669090271\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.5397675186395645, Generator Loss: 1.0238115787506104\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5381040275096893, Generator Loss: 0.9984875321388245\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.5653159022331238, Generator Loss: 1.0301132202148438\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.513126328587532, Generator Loss: 0.842192530632019\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5107197910547256, Generator Loss: 1.0395240783691406\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.4962349385023117, Generator Loss: 1.0353732109069824\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.5280377864837646, Generator Loss: 1.0394046306610107\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.5196276307106018, Generator Loss: 0.8425111770629883\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5770062506198883, Generator Loss: 0.9207589626312256\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5586760640144348, Generator Loss: 0.898990273475647\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5295002460479736, Generator Loss: 0.945614218711853\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5149591863155365, Generator Loss: 0.9884241819381714\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5251118540763855, Generator Loss: 0.9553146362304688\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5356977880001068, Generator Loss: 0.8709566593170166\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5894732028245926, Generator Loss: 1.0217251777648926\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5429818779230118, Generator Loss: 0.8941294550895691\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5182064175605774, Generator Loss: 0.927424430847168\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.581937313079834, Generator Loss: 0.9434593915939331\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5383614152669907, Generator Loss: 0.9474077224731445\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5379696935415268, Generator Loss: 0.9558860063552856\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5452463924884796, Generator Loss: 0.9410943984985352\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5535627901554108, Generator Loss: 1.003354787826538\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5184484422206879, Generator Loss: 1.001442790031433\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.551091730594635, Generator Loss: 0.8792390823364258\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5288247466087341, Generator Loss: 0.9137576818466187\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5296815931797028, Generator Loss: 0.9651172161102295\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5602581351995468, Generator Loss: 0.8877400159835815\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5454199016094208, Generator Loss: 0.8469229340553284\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.5649006068706512, Generator Loss: 0.8142805099487305\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5804252922534943, Generator Loss: 0.849417507648468\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5728092044591904, Generator Loss: 0.8642456531524658\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5242021977901459, Generator Loss: 0.8358597755432129\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5746015757322311, Generator Loss: 0.8969656229019165\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5732069760560989, Generator Loss: 0.8179985880851746\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.5883443057537079, Generator Loss: 0.889314591884613\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5671328604221344, Generator Loss: 0.8384577631950378\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5581998825073242, Generator Loss: 0.8445143103599548\n",
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [01:29<05:52, 22.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.6915817260742188, Generator Loss: 0.6731772422790527\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6728508174419403, Generator Loss: 0.663741946220398\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6542983055114746, Generator Loss: 0.654880702495575\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6462721228599548, Generator Loss: 0.6545936465263367\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6446073055267334, Generator Loss: 0.6344692707061768\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6318222284317017, Generator Loss: 0.6439971327781677\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6222837269306183, Generator Loss: 0.6382482051849365\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6085230559110641, Generator Loss: 0.6501373648643494\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6017437279224396, Generator Loss: 0.6479518413543701\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6035249382257462, Generator Loss: 0.6685848832130432\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6057950556278229, Generator Loss: 0.6670039892196655\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.5902186036109924, Generator Loss: 0.6881195902824402\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.5730474591255188, Generator Loss: 0.6898987293243408\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.5615308582782745, Generator Loss: 0.7054179310798645\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.5843282341957092, Generator Loss: 0.7280539870262146\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.5521144568920135, Generator Loss: 0.7220785617828369\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.5620847940444946, Generator Loss: 0.7285443544387817\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.5615623295307159, Generator Loss: 0.749748706817627\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.544163167476654, Generator Loss: 0.7455711364746094\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.577870711684227, Generator Loss: 0.7667869329452515\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.5664868652820587, Generator Loss: 0.7692475318908691\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.5463590025901794, Generator Loss: 0.7890341281890869\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.5468435138463974, Generator Loss: 0.7846059799194336\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.5407067984342575, Generator Loss: 0.8181012868881226\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.5502499043941498, Generator Loss: 0.8276429772377014\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.5236759781837463, Generator Loss: 0.8103864192962646\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.5706374645233154, Generator Loss: 0.9060227274894714\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5175321400165558, Generator Loss: 0.8331435918807983\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.514123797416687, Generator Loss: 0.9151216745376587\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.530500590801239, Generator Loss: 0.9193940162658691\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.5307431668043137, Generator Loss: 0.881587028503418\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.5015522688627243, Generator Loss: 0.8586176037788391\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5458238571882248, Generator Loss: 0.8559249639511108\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.4743989109992981, Generator Loss: 0.8847225904464722\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.503911018371582, Generator Loss: 0.9716264605522156\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5344051122665405, Generator Loss: 0.8846691846847534\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.4986560046672821, Generator Loss: 0.9581031203269958\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.4968709796667099, Generator Loss: 0.9562197327613831\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5467240512371063, Generator Loss: 0.976995587348938\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.5214398801326752, Generator Loss: 0.9666271209716797\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.4890097677707672, Generator Loss: 0.9674839973449707\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.517048791050911, Generator Loss: 0.953385591506958\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.49926455318927765, Generator Loss: 1.0672647953033447\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.4694920480251312, Generator Loss: 1.037057876586914\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.4799151122570038, Generator Loss: 1.0299252271652222\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.4948924630880356, Generator Loss: 1.033987045288086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.5155149698257446, Generator Loss: 1.0509990453720093\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5186002552509308, Generator Loss: 1.0646770000457764\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5120168924331665, Generator Loss: 1.0727587938308716\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.4818246364593506, Generator Loss: 1.1448845863342285\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5015735626220703, Generator Loss: 1.1753065586090088\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.4655207693576813, Generator Loss: 1.1352875232696533\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.5002864301204681, Generator Loss: 1.079416275024414\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.4700850546360016, Generator Loss: 1.0371379852294922\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.4482838362455368, Generator Loss: 1.0395475625991821\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.5110197961330414, Generator Loss: 1.1822280883789062\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.4794842302799225, Generator Loss: 1.109809160232544\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.44256846606731415, Generator Loss: 1.1009886264801025\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.46016183495521545, Generator Loss: 1.1943047046661377\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.47915390133857727, Generator Loss: 1.2727839946746826\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5089254975318909, Generator Loss: 1.1396318674087524\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.48556168377399445, Generator Loss: 1.1118968725204468\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.4894082248210907, Generator Loss: 1.1220358610153198\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.47340038418769836, Generator Loss: 1.3262851238250732\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.4746735990047455, Generator Loss: 1.120832920074463\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.49725574254989624, Generator Loss: 1.0640995502471924\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.45206937193870544, Generator Loss: 1.2422997951507568\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.43042218685150146, Generator Loss: 1.1810402870178223\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.47650645673274994, Generator Loss: 1.185229778289795\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.4952031970024109, Generator Loss: 1.2955554723739624\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.47552290558815, Generator Loss: 1.2137877941131592\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5078192800283432, Generator Loss: 1.2273328304290771\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.46253493428230286, Generator Loss: 1.1429904699325562\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5020221769809723, Generator Loss: 1.1725432872772217\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.47506460547447205, Generator Loss: 1.2479379177093506\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5098840594291687, Generator Loss: 1.2711399793624878\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.4829255938529968, Generator Loss: 1.1725118160247803\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.4460553675889969, Generator Loss: 1.1756963729858398\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.4924897104501724, Generator Loss: 1.1533699035644531\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.490908607840538, Generator Loss: 1.1052347421646118\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5086794793605804, Generator Loss: 1.113391399383545\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.45716822147369385, Generator Loss: 1.2939085960388184\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5060679465532303, Generator Loss: 1.0750170946121216\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.4745607078075409, Generator Loss: 1.145285725593567\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.47318151593208313, Generator Loss: 1.0338983535766602\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.4821433126926422, Generator Loss: 1.1005911827087402\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.4897768944501877, Generator Loss: 1.0778800249099731\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.45666229724884033, Generator Loss: 0.9951095581054688\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5144810676574707, Generator Loss: 1.1674611568450928\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5238277912139893, Generator Loss: 1.0113844871520996\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5155231952667236, Generator Loss: 1.0938332080841064\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.4939827620983124, Generator Loss: 1.1451811790466309\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5156950205564499, Generator Loss: 1.0756440162658691\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5001642107963562, Generator Loss: 1.0796029567718506\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5050584375858307, Generator Loss: 1.0953636169433594\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5048275589942932, Generator Loss: 1.0094079971313477\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5109051764011383, Generator Loss: 1.0877337455749512\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.47263240814208984, Generator Loss: 1.0418356657028198\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5058136731386185, Generator Loss: 1.0465928316116333\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.4751957505941391, Generator Loss: 1.049197793006897\n",
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [01:50<05:25, 21.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7026136517524719, Generator Loss: 0.6718229055404663\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.684342622756958, Generator Loss: 0.6546396613121033\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6797377169132233, Generator Loss: 0.646489143371582\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6692484319210052, Generator Loss: 0.637413740158081\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6644611656665802, Generator Loss: 0.6333940029144287\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6579921245574951, Generator Loss: 0.6285777688026428\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6513869166374207, Generator Loss: 0.6347477436065674\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.649969220161438, Generator Loss: 0.6396286487579346\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6416372358798981, Generator Loss: 0.6293659806251526\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6422383785247803, Generator Loss: 0.6336212158203125\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6494318842887878, Generator Loss: 0.6333456039428711\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6472282111644745, Generator Loss: 0.6352415084838867\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6401212215423584, Generator Loss: 0.6077426671981812\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6501736044883728, Generator Loss: 0.627500593662262\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6508942544460297, Generator Loss: 0.6247853636741638\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6504647433757782, Generator Loss: 0.6302784085273743\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.6375369131565094, Generator Loss: 0.64599609375\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6574257612228394, Generator Loss: 0.6368060111999512\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6555748581886292, Generator Loss: 0.6089770197868347\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.6577467918395996, Generator Loss: 0.6239686012268066\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6426923274993896, Generator Loss: 0.6366527080535889\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.650718629360199, Generator Loss: 0.6638516187667847\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.6508148312568665, Generator Loss: 0.6593793630599976\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.645786702632904, Generator Loss: 0.6548265218734741\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.641682505607605, Generator Loss: 0.648587703704834\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.6520698070526123, Generator Loss: 0.6438589096069336\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.6372623443603516, Generator Loss: 0.6861846446990967\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.6381811499595642, Generator Loss: 0.6737536191940308\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.6462117731571198, Generator Loss: 0.6783125996589661\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.6356193423271179, Generator Loss: 0.6947001218795776\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.6337721645832062, Generator Loss: 0.6940106749534607\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.6404682695865631, Generator Loss: 0.6896499991416931\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.6228074133396149, Generator Loss: 0.7197368144989014\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.6348954439163208, Generator Loss: 0.7049664855003357\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.6284782588481903, Generator Loss: 0.700234055519104\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.6386005282402039, Generator Loss: 0.7133601903915405\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.6333290040493011, Generator Loss: 0.710666298866272\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.6337712407112122, Generator Loss: 0.7489586472511292\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.6278235018253326, Generator Loss: 0.7381914854049683\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.6242311894893646, Generator Loss: 0.7236813902854919\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.6404655277729034, Generator Loss: 0.7443995475769043\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.6221727728843689, Generator Loss: 0.7349891662597656\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.6235849261283875, Generator Loss: 0.7179165482521057\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.6146454215049744, Generator Loss: 0.7609326839447021\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.6309930086135864, Generator Loss: 0.7467809915542603\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.6368595957756042, Generator Loss: 0.7396326065063477\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.6254754960536957, Generator Loss: 0.7472738027572632\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.6245290040969849, Generator Loss: 0.7637001276016235\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.6250290274620056, Generator Loss: 0.7438656091690063\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.6137229800224304, Generator Loss: 0.7506721615791321\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.6233703792095184, Generator Loss: 0.7481390237808228\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.6165372133255005, Generator Loss: 0.7451834678649902\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.6116733551025391, Generator Loss: 0.7697744965553284\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.6120716035366058, Generator Loss: 0.7678316235542297\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.6084970235824585, Generator Loss: 0.7677302360534668\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.6049486994743347, Generator Loss: 0.7859762907028198\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.6109669506549835, Generator Loss: 0.7804188132286072\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.6098623275756836, Generator Loss: 0.7668590545654297\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.6091156303882599, Generator Loss: 0.7690503597259521\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.6150322556495667, Generator Loss: 0.7669715881347656\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.6148743331432343, Generator Loss: 0.7479506134986877\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.6117100715637207, Generator Loss: 0.7690684795379639\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.6120738089084625, Generator Loss: 0.7844438552856445\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.6094201505184174, Generator Loss: 0.8120988011360168\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5972471833229065, Generator Loss: 0.8223940134048462\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.5988467931747437, Generator Loss: 0.775654673576355\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.605068027973175, Generator Loss: 0.7920706272125244\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5932357609272003, Generator Loss: 0.7840993404388428\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.601728618144989, Generator Loss: 0.7848885655403137\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.6049738824367523, Generator Loss: 0.7866038084030151\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.6027655303478241, Generator Loss: 0.8028252124786377\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.6037609279155731, Generator Loss: 0.788245677947998\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5997484922409058, Generator Loss: 0.7941675782203674\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5961197316646576, Generator Loss: 0.816801905632019\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5904846787452698, Generator Loss: 0.8153223395347595\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.6010152697563171, Generator Loss: 0.7968665361404419\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5936268270015717, Generator Loss: 0.788002610206604\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.6016402840614319, Generator Loss: 0.7932202816009521\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5945094227790833, Generator Loss: 0.7894662618637085\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5913495123386383, Generator Loss: 0.8277418613433838\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5912659466266632, Generator Loss: 0.821037769317627\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5810043215751648, Generator Loss: 0.824021577835083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5826480388641357, Generator Loss: 0.8178045749664307\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5719454884529114, Generator Loss: 0.838245689868927\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5851646959781647, Generator Loss: 0.8109122514724731\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5929149091243744, Generator Loss: 0.8270852565765381\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5843703150749207, Generator Loss: 0.8087854385375977\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5848088562488556, Generator Loss: 0.8364372253417969\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5762414634227753, Generator Loss: 0.83796226978302\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5645132064819336, Generator Loss: 0.8387479782104492\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5953162610530853, Generator Loss: 0.8087136745452881\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.567002683877945, Generator Loss: 0.8312033414840698\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5789439678192139, Generator Loss: 0.8523048758506775\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.578070878982544, Generator Loss: 0.8541856408119202\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5682212710380554, Generator Loss: 0.8775801658630371\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5645052790641785, Generator Loss: 0.8421663045883179\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5734722316265106, Generator Loss: 0.8453007936477661\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.5573401749134064, Generator Loss: 0.8374302387237549\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.561996579170227, Generator Loss: 0.8496081233024597\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5644219517707825, Generator Loss: 0.8529607653617859\n",
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [02:10<04:54, 21.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7090825438499451, Generator Loss: 0.6741133332252502\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6834333539009094, Generator Loss: 0.6590477824211121\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6703687906265259, Generator Loss: 0.653978168964386\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.658998966217041, Generator Loss: 0.6407551765441895\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6422251462936401, Generator Loss: 0.6390372514724731\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6417095065116882, Generator Loss: 0.6434258222579956\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6342623829841614, Generator Loss: 0.6454834342002869\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6133007705211639, Generator Loss: 0.6549434661865234\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6152119487524033, Generator Loss: 0.6584581732749939\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6076968312263489, Generator Loss: 0.6555708050727844\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.5921573638916016, Generator Loss: 0.6458498239517212\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.5967983901500702, Generator Loss: 0.6662565469741821\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.5886549949645996, Generator Loss: 0.689146876335144\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.5890601426362991, Generator Loss: 0.6908062696456909\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.5716740190982819, Generator Loss: 0.7165396213531494\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.5699332505464554, Generator Loss: 0.7000916004180908\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.5998858511447906, Generator Loss: 0.700897216796875\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.5602916032075882, Generator Loss: 0.7264745831489563\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.572155624628067, Generator Loss: 0.747877836227417\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.5396041721105576, Generator Loss: 0.7204883098602295\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.540764793753624, Generator Loss: 0.7307385802268982\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.5318258106708527, Generator Loss: 0.7227975130081177\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.5548086762428284, Generator Loss: 0.7431315183639526\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.5226136744022369, Generator Loss: 0.7727028727531433\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.551484078168869, Generator Loss: 0.7877485752105713\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.5494872778654099, Generator Loss: 0.767387330532074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.5278982371091843, Generator Loss: 0.7726070880889893\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5182918012142181, Generator Loss: 0.8566015958786011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.5560081005096436, Generator Loss: 0.8244192600250244\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.5269798785448074, Generator Loss: 0.8564321994781494\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.5097543597221375, Generator Loss: 0.8158762454986572\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.5498611629009247, Generator Loss: 0.8432034850120544\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5561218559741974, Generator Loss: 0.8399087190628052\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.5282744467258453, Generator Loss: 0.8564046621322632\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.5510960519313812, Generator Loss: 0.8806469440460205\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5043738186359406, Generator Loss: 0.8926423788070679\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.5009247958660126, Generator Loss: 0.8633769750595093\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5478016883134842, Generator Loss: 0.8393157124519348\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5145797729492188, Generator Loss: 0.8763906955718994\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.5056449323892593, Generator Loss: 0.933801531791687\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5508260130882263, Generator Loss: 0.8532513380050659\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.486247718334198, Generator Loss: 0.8778349161148071\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5027855932712555, Generator Loss: 0.9215694665908813\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.49587300419807434, Generator Loss: 0.9442604184150696\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.4921600818634033, Generator Loss: 0.9379667043685913\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.5580015033483505, Generator Loss: 0.9588583707809448\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.49944016337394714, Generator Loss: 0.9638824462890625\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5131311863660812, Generator Loss: 0.9809319376945496\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5133292078971863, Generator Loss: 0.9653072357177734\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5280776619911194, Generator Loss: 1.0573872327804565\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.52116858959198, Generator Loss: 0.9795650243759155\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.47276806831359863, Generator Loss: 1.0609164237976074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.5219022929668427, Generator Loss: 1.015421986579895\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.4992356598377228, Generator Loss: 1.0389854907989502\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5395701825618744, Generator Loss: 0.9605144262313843\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.48636099696159363, Generator Loss: 1.0182139873504639\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.5267525017261505, Generator Loss: 0.8840221762657166\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.48523280024528503, Generator Loss: 1.04542875289917\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5124303102493286, Generator Loss: 0.9540368914604187\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.4778026342391968, Generator Loss: 0.9134304523468018\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.49782803654670715, Generator Loss: 1.0134000778198242\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.4491688460111618, Generator Loss: 1.0362982749938965\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.5155771970748901, Generator Loss: 1.0089644193649292\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.46402549743652344, Generator Loss: 1.0038655996322632\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.46700605750083923, Generator Loss: 1.0338213443756104\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.48693181574344635, Generator Loss: 0.9845798015594482\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.4952061176300049, Generator Loss: 1.115850806236267\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5186561048030853, Generator Loss: 1.1162149906158447\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5250479280948639, Generator Loss: 1.0807236433029175\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.5071824342012405, Generator Loss: 1.114684820175171\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.47196707129478455, Generator Loss: 1.0834640264511108\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5063065588474274, Generator Loss: 0.978831946849823\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5158075392246246, Generator Loss: 1.0483016967773438\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5313477516174316, Generator Loss: 1.0236142873764038\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.49638551473617554, Generator Loss: 1.0620274543762207\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5170401334762573, Generator Loss: 1.1083018779754639\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5247036665678024, Generator Loss: 1.0698179006576538\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.49294668436050415, Generator Loss: 0.9543370008468628\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5239251554012299, Generator Loss: 1.0076439380645752\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.4772619903087616, Generator Loss: 1.116803526878357\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5155983418226242, Generator Loss: 1.065098524093628\n",
            "2/2 [==============================] - 0s 20ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5368986129760742, Generator Loss: 1.033765435218811\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.529225766658783, Generator Loss: 1.0742863416671753\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5508249998092651, Generator Loss: 1.052679419517517\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.4994317889213562, Generator Loss: 0.9586436748504639\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5357266366481781, Generator Loss: 0.9967712163925171\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5340846627950668, Generator Loss: 1.0230461359024048\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5249360352754593, Generator Loss: 1.0375621318817139\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5693343728780746, Generator Loss: 1.0240328311920166\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5198993980884552, Generator Loss: 1.0807456970214844\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5051106065511703, Generator Loss: 0.9651771783828735\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.4928695559501648, Generator Loss: 0.9910433292388916\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5069460421800613, Generator Loss: 0.9713246822357178\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5520427078008652, Generator Loss: 0.9938685894012451\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5130006074905396, Generator Loss: 0.9812160730361938\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5295833051204681, Generator Loss: 0.992854118347168\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.49817976355552673, Generator Loss: 0.9989100694656372\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.606533020734787, Generator Loss: 1.045498013496399\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5285471677780151, Generator Loss: 0.9474136829376221\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5624307841062546, Generator Loss: 0.9594339728355408\n",
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [02:32<04:39, 21.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.6690589189529419, Generator Loss: 0.6308699250221252\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6502440571784973, Generator Loss: 0.6226401925086975\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6462544500827789, Generator Loss: 0.6115673184394836\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6442885994911194, Generator Loss: 0.598915159702301\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6472734212875366, Generator Loss: 0.6126511693000793\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6384005546569824, Generator Loss: 0.6038498282432556\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6421326696872711, Generator Loss: 0.5953515768051147\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6388182938098907, Generator Loss: 0.6077585816383362\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6411140710115433, Generator Loss: 0.618368923664093\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6443873345851898, Generator Loss: 0.6057693362236023\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6374450474977493, Generator Loss: 0.620331883430481\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6373124271631241, Generator Loss: 0.6197048425674438\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6355489492416382, Generator Loss: 0.6239704489707947\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6263256072998047, Generator Loss: 0.6225650906562805\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6350751668214798, Generator Loss: 0.6357898116111755\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.623119592666626, Generator Loss: 0.6484870314598083\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.6398342847824097, Generator Loss: 0.6501328945159912\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6080478727817535, Generator Loss: 0.6359512805938721\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6321776211261749, Generator Loss: 0.6637632250785828\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.6042829155921936, Generator Loss: 0.657302737236023\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6368764638900757, Generator Loss: 0.6444591283798218\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.6250806152820587, Generator Loss: 0.6801532506942749\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.6287083625793457, Generator Loss: 0.6813995838165283\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.6380718946456909, Generator Loss: 0.6896213293075562\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.6394572556018829, Generator Loss: 0.6927878856658936\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.6149967312812805, Generator Loss: 0.6876859664916992\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.6138632893562317, Generator Loss: 0.6881610751152039\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.6009231060743332, Generator Loss: 0.696399986743927\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.5961281359195709, Generator Loss: 0.7465170621871948\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.6181561350822449, Generator Loss: 0.7157279253005981\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.6116507351398468, Generator Loss: 0.7366479635238647\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.6143034994602203, Generator Loss: 0.7506307363510132\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.6282746195793152, Generator Loss: 0.7696749567985535\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.6083662509918213, Generator Loss: 0.756077766418457\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.5917505621910095, Generator Loss: 0.7506958246231079\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.6266233026981354, Generator Loss: 0.7597836852073669\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.5922743678092957, Generator Loss: 0.7486622333526611\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.6069824993610382, Generator Loss: 0.7440317273139954\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5825098156929016, Generator Loss: 0.7617822885513306\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.5940287411212921, Generator Loss: 0.7769579291343689\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5759350955486298, Generator Loss: 0.7997951507568359\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.569902777671814, Generator Loss: 0.7724009156227112\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.6046962738037109, Generator Loss: 0.7925899028778076\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.6064347624778748, Generator Loss: 0.8075731992721558\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.6179178953170776, Generator Loss: 0.812811017036438\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.6046042442321777, Generator Loss: 0.7704343795776367\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.584600418806076, Generator Loss: 0.7967507839202881\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5901423096656799, Generator Loss: 0.8043584823608398\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.6067826747894287, Generator Loss: 0.8118985891342163\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.596577525138855, Generator Loss: 0.81602942943573\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5768769979476929, Generator Loss: 0.8105829954147339\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.6132825613021851, Generator Loss: 0.8225805759429932\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.584360808134079, Generator Loss: 0.8212318420410156\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5928871631622314, Generator Loss: 0.858704686164856\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5991861820220947, Generator Loss: 0.7969384789466858\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.598653644323349, Generator Loss: 0.8190670013427734\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.5998010635375977, Generator Loss: 0.821287989616394\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.5842194855213165, Generator Loss: 0.857107937335968\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5873882472515106, Generator Loss: 0.8046255707740784\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5804632604122162, Generator Loss: 0.8643364906311035\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5944876670837402, Generator Loss: 0.8198511004447937\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.596589207649231, Generator Loss: 0.8338525295257568\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.6067059636116028, Generator Loss: 0.8265453577041626\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.5755665600299835, Generator Loss: 0.8678163886070251\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5716375708580017, Generator Loss: 0.9179888367652893\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.5642875134944916, Generator Loss: 0.7960668802261353\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.5687852203845978, Generator Loss: 0.865507960319519\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.557849258184433, Generator Loss: 0.8495324850082397\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5537106692790985, Generator Loss: 0.8306310176849365\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.5753293633460999, Generator Loss: 0.8408628702163696\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.5587433576583862, Generator Loss: 0.8433083295822144\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5661790370941162, Generator Loss: 0.8467813730239868\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5508690476417542, Generator Loss: 0.8918788433074951\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5766156613826752, Generator Loss: 0.8687787055969238\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5604504942893982, Generator Loss: 0.8469013571739197\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5637694001197815, Generator Loss: 0.8999825119972229\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5623461306095123, Generator Loss: 0.8712328672409058\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5528958141803741, Generator Loss: 0.8992594480514526\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5654537081718445, Generator Loss: 0.9172123670578003\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5460634231567383, Generator Loss: 0.8889127373695374\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5439494252204895, Generator Loss: 0.9270713329315186\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5651187896728516, Generator Loss: 0.817305326461792\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5476509928703308, Generator Loss: 0.8969188332557678\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5602044761180878, Generator Loss: 0.893661618232727\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5392866134643555, Generator Loss: 0.9025402069091797\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5673224925994873, Generator Loss: 0.8936847448348999\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5467312335968018, Generator Loss: 0.9442983269691467\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5848293304443359, Generator Loss: 0.9132125377655029\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5501464307308197, Generator Loss: 0.8641815185546875\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5410577058792114, Generator Loss: 0.8914271593093872\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.516220897436142, Generator Loss: 0.8885767459869385\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.5345840752124786, Generator Loss: 0.9034436941146851\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.553086668252945, Generator Loss: 0.9039800763130188\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.537628561258316, Generator Loss: 0.9217811822891235\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5457918047904968, Generator Loss: 0.9447996616363525\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5360493659973145, Generator Loss: 0.9166790843009949\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5280146598815918, Generator Loss: 0.9511368870735168\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.5382194221019745, Generator Loss: 0.9497091174125671\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5439232289791107, Generator Loss: 0.9189749360084534\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5244773030281067, Generator Loss: 0.9095978736877441\n",
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [02:52<04:10, 20.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.6825616657733917, Generator Loss: 0.6368058919906616\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6625739336013794, Generator Loss: 0.6179834604263306\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6482400298118591, Generator Loss: 0.6058043241500854\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6427519917488098, Generator Loss: 0.5985625386238098\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6556447744369507, Generator Loss: 0.5870144963264465\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6514685451984406, Generator Loss: 0.5887978076934814\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6426917910575867, Generator Loss: 0.5718897581100464\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6468710899353027, Generator Loss: 0.5992202758789062\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6523478925228119, Generator Loss: 0.5915321111679077\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6442838609218597, Generator Loss: 0.5835136771202087\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6505774110555649, Generator Loss: 0.6118958592414856\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6470538675785065, Generator Loss: 0.6098668575286865\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6561600565910339, Generator Loss: 0.597866415977478\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6420161128044128, Generator Loss: 0.6099464893341064\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6482899785041809, Generator Loss: 0.6138437986373901\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6452725827693939, Generator Loss: 0.6213021278381348\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.639433354139328, Generator Loss: 0.6514749526977539\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6313096582889557, Generator Loss: 0.6520059108734131\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6367479264736176, Generator Loss: 0.649134635925293\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.6354313790798187, Generator Loss: 0.6604352593421936\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6292214542627335, Generator Loss: 0.6664913892745972\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.6115743964910507, Generator Loss: 0.6963250041007996\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.6140536963939667, Generator Loss: 0.7023564577102661\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.6087965071201324, Generator Loss: 0.7112905383110046\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.6133289337158203, Generator Loss: 0.726898729801178\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.6130495071411133, Generator Loss: 0.7195993065834045\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.616001158952713, Generator Loss: 0.7089535593986511\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5987164378166199, Generator Loss: 0.7581347227096558\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.6152249872684479, Generator Loss: 0.7751516699790955\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.6094270944595337, Generator Loss: 0.7487529516220093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.5957093238830566, Generator Loss: 0.7551199197769165\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.585902601480484, Generator Loss: 0.7600672245025635\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.6090865731239319, Generator Loss: 0.8112055659294128\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.6144022643566132, Generator Loss: 0.7624030113220215\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.5779320299625397, Generator Loss: 0.8119210600852966\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5931009352207184, Generator Loss: 0.7507212162017822\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.5850375592708588, Generator Loss: 0.785362958908081\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5878950655460358, Generator Loss: 0.7771903276443481\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5940542221069336, Generator Loss: 0.7886549234390259\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.6132764220237732, Generator Loss: 0.7662561535835266\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.59187251329422, Generator Loss: 0.8436763286590576\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.6011739671230316, Generator Loss: 0.798698902130127\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5760082006454468, Generator Loss: 0.8194730281829834\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.5614931881427765, Generator Loss: 0.813511848449707\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.581707239151001, Generator Loss: 0.8283762335777283\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.5976392924785614, Generator Loss: 0.803816020488739\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.567162036895752, Generator Loss: 0.8298130631446838\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5846832692623138, Generator Loss: 0.8126174807548523\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.559855043888092, Generator Loss: 0.8458164930343628\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5882726311683655, Generator Loss: 0.8147727847099304\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5783447623252869, Generator Loss: 0.7576594352722168\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.5775058269500732, Generator Loss: 0.8093476891517639\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.5871188044548035, Generator Loss: 0.7763500213623047\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5680709183216095, Generator Loss: 0.8034098744392395\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5684042870998383, Generator Loss: 0.8070932626724243\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.6064301133155823, Generator Loss: 0.8471240401268005\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.58992138504982, Generator Loss: 0.8558862209320068\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.5877639055252075, Generator Loss: 0.7916932106018066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5757179856300354, Generator Loss: 0.8302583694458008\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5816560387611389, Generator Loss: 0.8119032979011536\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5810871124267578, Generator Loss: 0.8227614164352417\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5763417482376099, Generator Loss: 0.8588271141052246\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.5852055549621582, Generator Loss: 0.8666619062423706\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.564046174287796, Generator Loss: 0.8314775228500366\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5787093639373779, Generator Loss: 0.7704370021820068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.585562527179718, Generator Loss: 0.8797246813774109\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.5714990794658661, Generator Loss: 0.8160692453384399\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5870004892349243, Generator Loss: 0.7839213013648987\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5822208821773529, Generator Loss: 0.8106492757797241\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.628105878829956, Generator Loss: 0.9058141708374023\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.602451890707016, Generator Loss: 0.8753733038902283\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5615777373313904, Generator Loss: 0.8407374620437622\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5376003384590149, Generator Loss: 0.8329964876174927\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5853643417358398, Generator Loss: 0.904107391834259\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5934925675392151, Generator Loss: 0.8460574746131897\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5732468068599701, Generator Loss: 0.8430281281471252\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.532878503203392, Generator Loss: 0.8809603452682495\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5919156074523926, Generator Loss: 0.8471124172210693\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5993627607822418, Generator Loss: 0.8759005069732666\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5726878941059113, Generator Loss: 0.8534026741981506\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5698352158069611, Generator Loss: 0.8989025354385376\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5822015106678009, Generator Loss: 0.8457187414169312\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5875908434391022, Generator Loss: 0.8298174142837524\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5740062594413757, Generator Loss: 0.8374398350715637\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5969951152801514, Generator Loss: 0.8227812051773071\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.6169050633907318, Generator Loss: 0.8239932656288147\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.6048118472099304, Generator Loss: 0.8306194543838501\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5771114826202393, Generator Loss: 0.8438379764556885\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5891624093055725, Generator Loss: 0.861320436000824\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.6142077445983887, Generator Loss: 0.8229066133499146\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5870771110057831, Generator Loss: 0.8285340666770935\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.6004661917686462, Generator Loss: 0.8253819346427917\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5788806676864624, Generator Loss: 0.8097237348556519\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5798878371715546, Generator Loss: 0.8223803043365479\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.58669313788414, Generator Loss: 0.8230518698692322\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.6004433631896973, Generator Loss: 0.867189347743988\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5984892547130585, Generator Loss: 0.9145082235336304\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.5717535614967346, Generator Loss: 0.8620316982269287\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.573523998260498, Generator Loss: 0.8472070097923279\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5682983696460724, Generator Loss: 0.837188720703125\n",
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [03:12<03:47, 20.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.6829325258731842, Generator Loss: 0.646953821182251\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6565643548965454, Generator Loss: 0.6384515762329102\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.646503210067749, Generator Loss: 0.6309069395065308\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6364753246307373, Generator Loss: 0.6225513219833374\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.631149560213089, Generator Loss: 0.6230634450912476\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6311325281858444, Generator Loss: 0.612008810043335\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6240815818309784, Generator Loss: 0.61969393491745\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6251490265130997, Generator Loss: 0.6221103668212891\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6255819797515869, Generator Loss: 0.615384578704834\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6273540705442429, Generator Loss: 0.6231707334518433\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6226718425750732, Generator Loss: 0.6513428688049316\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6121571362018585, Generator Loss: 0.6218703389167786\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6486045122146606, Generator Loss: 0.6485766768455505\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6043345481157303, Generator Loss: 0.629618763923645\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6282201409339905, Generator Loss: 0.6429451107978821\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6147103607654572, Generator Loss: 0.6463490724563599\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.6160114705562592, Generator Loss: 0.6634531021118164\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.604811429977417, Generator Loss: 0.6330732107162476\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6234520673751831, Generator Loss: 0.6703222990036011\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.6134783327579498, Generator Loss: 0.6875691413879395\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6135640144348145, Generator Loss: 0.6987137794494629\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.5761120766401291, Generator Loss: 0.7111443281173706\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.6131017804145813, Generator Loss: 0.716793417930603\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.603575810790062, Generator Loss: 0.7179891467094421\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.5902010947465897, Generator Loss: 0.7443408966064453\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.593434527516365, Generator Loss: 0.7487382292747498\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.5841653347015381, Generator Loss: 0.7832004427909851\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5756669640541077, Generator Loss: 0.7968726754188538\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.5782901644706726, Generator Loss: 0.776622474193573\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.5641691088676453, Generator Loss: 0.7935792207717896\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.6025201678276062, Generator Loss: 0.7815969586372375\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.6073707044124603, Generator Loss: 0.7936587929725647\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5773923397064209, Generator Loss: 0.7840995788574219\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.5820781886577606, Generator Loss: 0.7655777931213379\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.6110777854919434, Generator Loss: 0.8075973987579346\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5731959939002991, Generator Loss: 0.859117865562439\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.586190938949585, Generator Loss: 0.7832683324813843\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5689296126365662, Generator Loss: 0.8470640778541565\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5932823419570923, Generator Loss: 0.8277851343154907\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.6214641630649567, Generator Loss: 0.8104642629623413\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5818099677562714, Generator Loss: 0.8438060283660889\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.6195079386234283, Generator Loss: 0.8034653663635254\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5820822715759277, Generator Loss: 0.8323360681533813\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.5824886560440063, Generator Loss: 0.8415498733520508\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.5979692041873932, Generator Loss: 0.8220369815826416\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.6041150689125061, Generator Loss: 0.8339130282402039\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.5735860168933868, Generator Loss: 0.8509830832481384\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.6307721734046936, Generator Loss: 0.8615611791610718\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5783533751964569, Generator Loss: 0.7803239226341248\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.6045773923397064, Generator Loss: 0.8289676904678345\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5984805822372437, Generator Loss: 0.8026405572891235\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.658759206533432, Generator Loss: 0.800298810005188\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.5807879567146301, Generator Loss: 0.8370239734649658\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5797284245491028, Generator Loss: 0.7856926918029785\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5841283798217773, Generator Loss: 0.8608368039131165\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.6392145156860352, Generator Loss: 0.8005601167678833\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.6252518594264984, Generator Loss: 0.808745265007019\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.6070135533809662, Generator Loss: 0.8726111650466919\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.6177418828010559, Generator Loss: 0.8083140850067139\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.6162678599357605, Generator Loss: 0.8596422672271729\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.6109370589256287, Generator Loss: 0.822837233543396\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5831909477710724, Generator Loss: 0.8225127458572388\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.6116911172866821, Generator Loss: 0.7760728597640991\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.620117574930191, Generator Loss: 0.8315057754516602\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5734148621559143, Generator Loss: 0.8317461609840393\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.6108876168727875, Generator Loss: 0.8094109296798706\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.6301600635051727, Generator Loss: 0.8174620270729065\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.6198289096355438, Generator Loss: 0.8075329065322876\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.6375703513622284, Generator Loss: 0.7963460087776184\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.5836170315742493, Generator Loss: 0.7972205877304077\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.6287992000579834, Generator Loss: 0.8197289109230042\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.6105673909187317, Generator Loss: 0.7626662254333496\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.6125587522983551, Generator Loss: 0.8117587566375732\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.6233997344970703, Generator Loss: 0.7979825735092163\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5935629904270172, Generator Loss: 0.7923057079315186\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.6056916117668152, Generator Loss: 0.7654771208763123\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.6100387275218964, Generator Loss: 0.7675894498825073\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.6009131669998169, Generator Loss: 0.8182960748672485\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5697323977947235, Generator Loss: 0.8327373266220093\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.6323667466640472, Generator Loss: 0.7635908126831055\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5938803553581238, Generator Loss: 0.8236367702484131\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5864171385765076, Generator Loss: 0.8282197713851929\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.6425666511058807, Generator Loss: 0.787564218044281\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.6785127818584442, Generator Loss: 0.8317133188247681\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5831891000270844, Generator Loss: 0.7789642810821533\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.6374070346355438, Generator Loss: 0.8089642524719238\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5991153120994568, Generator Loss: 0.8193572163581848\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5711654424667358, Generator Loss: 0.8086405992507935\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.6076239943504333, Generator Loss: 0.7996945381164551\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.6086018979549408, Generator Loss: 0.7955158352851868\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.583350658416748, Generator Loss: 0.7711551189422607\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.6292565166950226, Generator Loss: 0.7972844243049622\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.6167015731334686, Generator Loss: 0.7806748151779175\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5779103636741638, Generator Loss: 0.7915410399436951\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.6247202157974243, Generator Loss: 0.8087903261184692\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.6342217028141022, Generator Loss: 0.8102166652679443\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.6583726406097412, Generator Loss: 0.8158156871795654\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.6033292710781097, Generator Loss: 0.8141940832138062\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.6146499216556549, Generator Loss: 0.8121851682662964\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.6149275898933411, Generator Loss: 0.7997493743896484\n",
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [03:32<03:22, 20.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7033116817474365, Generator Loss: 0.651827335357666\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6772564351558685, Generator Loss: 0.6412369012832642\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6630719304084778, Generator Loss: 0.6298925280570984\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6569788455963135, Generator Loss: 0.6275601387023926\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6458679735660553, Generator Loss: 0.6154823303222656\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6338475346565247, Generator Loss: 0.6207281351089478\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6292112171649933, Generator Loss: 0.6292819976806641\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.620043158531189, Generator Loss: 0.6308708190917969\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6208648085594177, Generator Loss: 0.6391309499740601\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.5945987403392792, Generator Loss: 0.6441988945007324\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6261219084262848, Generator Loss: 0.6367196440696716\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6075995564460754, Generator Loss: 0.6561892628669739\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.632981687784195, Generator Loss: 0.6592465043067932\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.60747230052948, Generator Loss: 0.6545860767364502\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.5943714082241058, Generator Loss: 0.6707107424736023\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6014390736818314, Generator Loss: 0.6576403379440308\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.6032033711671829, Generator Loss: 0.684496283531189\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6109405755996704, Generator Loss: 0.6929997205734253\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6139100790023804, Generator Loss: 0.6848801374435425\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.5793551951646805, Generator Loss: 0.6987757086753845\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6074255406856537, Generator Loss: 0.7071099281311035\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.5829541832208633, Generator Loss: 0.7186073660850525\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.619370698928833, Generator Loss: 0.7316545248031616\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.5997817069292068, Generator Loss: 0.7275005578994751\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.5937966406345367, Generator Loss: 0.7390713691711426\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.6022931635379791, Generator Loss: 0.7409140467643738\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.599828377366066, Generator Loss: 0.7610111832618713\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5548248142004013, Generator Loss: 0.7448842525482178\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.6147436797618866, Generator Loss: 0.7877012491226196\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.5989317297935486, Generator Loss: 0.7804725170135498\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.5963849723339081, Generator Loss: 0.7678816318511963\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.5982188880443573, Generator Loss: 0.7834711074829102\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5959798097610474, Generator Loss: 0.7953909635543823\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.5757623314857483, Generator Loss: 0.8538780212402344\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.5927786231040955, Generator Loss: 0.8078131675720215\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5626613795757294, Generator Loss: 0.809306263923645\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.589018851518631, Generator Loss: 0.8625643849372864\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5979699492454529, Generator Loss: 0.8205029964447021\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5615338385105133, Generator Loss: 0.8305146098136902\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.5623667240142822, Generator Loss: 0.7969430685043335\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5624527633190155, Generator Loss: 0.8111046552658081\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.6212392747402191, Generator Loss: 0.8075985908508301\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5879622101783752, Generator Loss: 0.8419159054756165\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.5784389674663544, Generator Loss: 0.8522562980651855\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.6035426259040833, Generator Loss: 0.8452839851379395\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.6021997928619385, Generator Loss: 0.8980041146278381\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.5870953500270844, Generator Loss: 0.8576335906982422\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5813824832439423, Generator Loss: 0.8380712270736694\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5908535718917847, Generator Loss: 0.8690139055252075\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5707651674747467, Generator Loss: 0.8332123756408691\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5567198991775513, Generator Loss: 0.8529196381568909\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.5475125014781952, Generator Loss: 0.8565924167633057\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.608016848564148, Generator Loss: 0.859375\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5514018535614014, Generator Loss: 0.9136956334114075\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5588835179805756, Generator Loss: 0.8367379903793335\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.5649585723876953, Generator Loss: 0.8817859888076782\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.6009035110473633, Generator Loss: 0.8819632530212402\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.5522679388523102, Generator Loss: 0.8633856177330017\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5540496110916138, Generator Loss: 0.8369770646095276\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5623398423194885, Generator Loss: 0.892397403717041\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5825513005256653, Generator Loss: 0.866098165512085\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5532832443714142, Generator Loss: 0.8711919784545898\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.5373829454183578, Generator Loss: 0.8594998717308044\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.5730776786804199, Generator Loss: 0.9160943031311035\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5891092419624329, Generator Loss: 0.8647633790969849\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.5463740825653076, Generator Loss: 0.9262375831604004\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.6024453639984131, Generator Loss: 0.865898609161377\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5307150334119797, Generator Loss: 0.8700205683708191\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5659304857254028, Generator Loss: 0.8900424242019653\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.5671122074127197, Generator Loss: 0.8438920974731445\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.5887413322925568, Generator Loss: 0.8815727233886719\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5669899582862854, Generator Loss: 0.8691651225090027\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5526337027549744, Generator Loss: 0.8924828767776489\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5909472703933716, Generator Loss: 0.8355951309204102\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5622615814208984, Generator Loss: 0.907418966293335\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5384373068809509, Generator Loss: 0.8798505067825317\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5710425674915314, Generator Loss: 0.8838950395584106\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5572981834411621, Generator Loss: 0.8422025442123413\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.6047869324684143, Generator Loss: 0.903728723526001\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5819424688816071, Generator Loss: 0.893906831741333\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.587021142244339, Generator Loss: 0.8861827850341797\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.6024340391159058, Generator Loss: 0.8842170834541321\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5847674906253815, Generator Loss: 0.864643931388855\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5946291983127594, Generator Loss: 0.8196681141853333\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.574545830488205, Generator Loss: 0.8434418439865112\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5453532934188843, Generator Loss: 0.8961405754089355\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5594777166843414, Generator Loss: 0.851243257522583\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5892763733863831, Generator Loss: 0.8741992115974426\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.6004847288131714, Generator Loss: 0.8743946552276611\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5863242745399475, Generator Loss: 0.8783179521560669\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5805653929710388, Generator Loss: 0.8346784114837646\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.5745268762111664, Generator Loss: 0.8093805313110352\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5573963224887848, Generator Loss: 0.8548780679702759\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5739602446556091, Generator Loss: 0.8684203028678894\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.577846348285675, Generator Loss: 0.8263322710990906\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5896433591842651, Generator Loss: 0.8822806477546692\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5690424144268036, Generator Loss: 0.8435633778572083\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.5781442523002625, Generator Loss: 0.8312839269638062\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5690594911575317, Generator Loss: 0.8591153621673584\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5858033895492554, Generator Loss: 0.8673741817474365\n",
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [03:52<03:02, 20.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7088771760463715, Generator Loss: 0.6935641169548035\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6870428621768951, Generator Loss: 0.6831454038619995\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6718135178089142, Generator Loss: 0.6772928833961487\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6680159270763397, Generator Loss: 0.670212984085083\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6570375859737396, Generator Loss: 0.6577284932136536\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6454300284385681, Generator Loss: 0.6685011386871338\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6408607959747314, Generator Loss: 0.6638929843902588\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.632102370262146, Generator Loss: 0.6638879776000977\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.633425772190094, Generator Loss: 0.6725481748580933\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6230074167251587, Generator Loss: 0.6765583753585815\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6070641875267029, Generator Loss: 0.6814275979995728\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6085761785507202, Generator Loss: 0.6891113519668579\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6003578305244446, Generator Loss: 0.6882584095001221\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6167267262935638, Generator Loss: 0.6767436265945435\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6317533999681473, Generator Loss: 0.6912486553192139\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6050214022397995, Generator Loss: 0.7038729786872864\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.5946992933750153, Generator Loss: 0.7043596506118774\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.594394326210022, Generator Loss: 0.6978975534439087\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6077721416950226, Generator Loss: 0.7019025683403015\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.5908048450946808, Generator Loss: 0.7333006858825684\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.5859270393848419, Generator Loss: 0.7224530577659607\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.5995355248451233, Generator Loss: 0.7502584457397461\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.5770552307367325, Generator Loss: 0.7436333894729614\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.5903414189815521, Generator Loss: 0.7250168323516846\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.591818243265152, Generator Loss: 0.7022473812103271\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.5705026090145111, Generator Loss: 0.7773446440696716\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.5941732823848724, Generator Loss: 0.7498083114624023\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5891461819410324, Generator Loss: 0.728367805480957\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.5822730362415314, Generator Loss: 0.775504469871521\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.573034793138504, Generator Loss: 0.7992839217185974\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.5460565388202667, Generator Loss: 0.7550938129425049\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.58498615026474, Generator Loss: 0.7843027114868164\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5799478441476822, Generator Loss: 0.8114741444587708\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.5901316404342651, Generator Loss: 0.7894513607025146\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.5925393402576447, Generator Loss: 0.7994012832641602\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5678607821464539, Generator Loss: 0.7676104307174683\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.5605078339576721, Generator Loss: 0.81931471824646\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.542754277586937, Generator Loss: 0.8412555456161499\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5230925679206848, Generator Loss: 0.7986467480659485\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.5481374114751816, Generator Loss: 0.8631153702735901\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5521642118692398, Generator Loss: 0.8473284244537354\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.5553618520498276, Generator Loss: 0.8446874618530273\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5606051087379456, Generator Loss: 0.8263589143753052\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.5529454052448273, Generator Loss: 0.942280650138855\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.5446058213710785, Generator Loss: 0.9088448882102966\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.5408875346183777, Generator Loss: 0.9229885935783386\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.5526999831199646, Generator Loss: 0.8800070285797119\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5439000576734543, Generator Loss: 0.9024478793144226\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5339781641960144, Generator Loss: 0.901599645614624\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5463006496429443, Generator Loss: 0.9020473957061768\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5648498237133026, Generator Loss: 0.9530261754989624\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.5782896876335144, Generator Loss: 0.9029319286346436\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.5748507082462311, Generator Loss: 0.8546227216720581\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5483025312423706, Generator Loss: 0.8866757154464722\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5853784382343292, Generator Loss: 0.9065557718276978\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.5757774114608765, Generator Loss: 0.920391857624054\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.5735252797603607, Generator Loss: 0.8897871971130371\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.5464284718036652, Generator Loss: 0.9583703279495239\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5422043800354004, Generator Loss: 0.9357554912567139\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5441360622644424, Generator Loss: 0.8723968267440796\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5532144010066986, Generator Loss: 0.9097718000411987\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5765744149684906, Generator Loss: 0.8547664880752563\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.5252696871757507, Generator Loss: 0.9735327959060669\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.5527185201644897, Generator Loss: 0.8399043083190918\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.569717213511467, Generator Loss: 0.8704907894134521\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.5515621900558472, Generator Loss: 0.9826417565345764\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.5655843019485474, Generator Loss: 0.9881772398948669\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5298869013786316, Generator Loss: 0.8388856053352356\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5611277967691422, Generator Loss: 0.8842415809631348\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.6115708649158478, Generator Loss: 0.8916112184524536\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.5653163194656372, Generator Loss: 0.8371520638465881\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5843080282211304, Generator Loss: 0.9019713401794434\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5900702327489853, Generator Loss: 0.9521361589431763\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5349043309688568, Generator Loss: 0.8834299445152283\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5979631543159485, Generator Loss: 0.864323616027832\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5843269228935242, Generator Loss: 0.8553074598312378\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5951032936573029, Generator Loss: 0.8411440849304199\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5767391324043274, Generator Loss: 0.8888921141624451\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5896254181861877, Generator Loss: 0.9635998010635376\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.610600084066391, Generator Loss: 0.9482844471931458\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.6394820809364319, Generator Loss: 0.77540123462677\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5856916606426239, Generator Loss: 0.8683559894561768\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5644088536500931, Generator Loss: 0.7842692732810974\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.6163582801818848, Generator Loss: 0.7908809185028076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5668049454689026, Generator Loss: 0.8616341352462769\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.6359349191188812, Generator Loss: 0.7778200507164001\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.6188732981681824, Generator Loss: 0.7484604120254517\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.6080384254455566, Generator Loss: 0.8063013553619385\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5889346301555634, Generator Loss: 0.8307746648788452\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.6256333291530609, Generator Loss: 0.8326715230941772\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.6046199202537537, Generator Loss: 0.7699389457702637\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.5917371660470963, Generator Loss: 0.8309571146965027\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5915761291980743, Generator Loss: 0.8686948418617249\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5872122645378113, Generator Loss: 0.8298061490058899\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.6062138080596924, Generator Loss: 0.8186858892440796\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5759928822517395, Generator Loss: 0.8127562999725342\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5983323454856873, Generator Loss: 0.8501684069633484\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.581801027059555, Generator Loss: 0.8396216630935669\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5818026661872864, Generator Loss: 0.8044477105140686\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5604195594787598, Generator Loss: 0.7526674866676331\n",
            "8/8 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [04:11<02:39, 19.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.6903998255729675, Generator Loss: 0.6735700368881226\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.673225462436676, Generator Loss: 0.6577563285827637\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6595346927642822, Generator Loss: 0.6448900699615479\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6504340171813965, Generator Loss: 0.6445736885070801\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6443681418895721, Generator Loss: 0.6286698579788208\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6376039683818817, Generator Loss: 0.6279627084732056\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6350698471069336, Generator Loss: 0.6298864483833313\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6384687423706055, Generator Loss: 0.6377905607223511\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6325261145830154, Generator Loss: 0.6403279304504395\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6246466636657715, Generator Loss: 0.6355941295623779\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6176609545946121, Generator Loss: 0.6539019346237183\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6032571345567703, Generator Loss: 0.645797610282898\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.607976108789444, Generator Loss: 0.6517695784568787\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6155966967344284, Generator Loss: 0.6686562895774841\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.606717973947525, Generator Loss: 0.6772395372390747\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.5919482260942459, Generator Loss: 0.671999990940094\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.6157864481210709, Generator Loss: 0.6797077655792236\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6027611643075943, Generator Loss: 0.6928721070289612\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6086360812187195, Generator Loss: 0.7134441137313843\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.5876627415418625, Generator Loss: 0.7005125284194946\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.5818430483341217, Generator Loss: 0.6831008195877075\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.5620075166225433, Generator Loss: 0.7384249567985535\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.5902837812900543, Generator Loss: 0.744797945022583\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.5694713741540909, Generator Loss: 0.7790905237197876\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.5915653556585312, Generator Loss: 0.7581319212913513\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.5646481812000275, Generator Loss: 0.7793548703193665\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.5737105906009674, Generator Loss: 0.7767717838287354\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5734645873308182, Generator Loss: 0.7964938879013062\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.5441648364067078, Generator Loss: 0.8083868622779846\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.5861139595508575, Generator Loss: 0.791348934173584\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.5523487627506256, Generator Loss: 0.8217576742172241\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.558450311422348, Generator Loss: 0.8383245468139648\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5722328126430511, Generator Loss: 0.873863935470581\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.5664387941360474, Generator Loss: 0.7914749383926392\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.5731001049280167, Generator Loss: 0.8358593583106995\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5523577928543091, Generator Loss: 0.8349196314811707\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.5242572128772736, Generator Loss: 0.8862090110778809\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5639301091432571, Generator Loss: 0.8924418091773987\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.5480145514011383, Generator Loss: 0.8575472831726074\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.5716962516307831, Generator Loss: 0.8723279237747192\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5257456004619598, Generator Loss: 0.9101434946060181\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.5120866596698761, Generator Loss: 0.8757779598236084\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5490827560424805, Generator Loss: 0.9059582352638245\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.5460206270217896, Generator Loss: 0.8829240798950195\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.5816399157047272, Generator Loss: 0.929408848285675\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.515280470252037, Generator Loss: 0.9328088164329529\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.5158693790435791, Generator Loss: 0.9696105718612671\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5497868061065674, Generator Loss: 0.92435222864151\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5102425664663315, Generator Loss: 0.9283412098884583\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.4933454990386963, Generator Loss: 0.9001636505126953\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5123047530651093, Generator Loss: 0.9378404021263123\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.5588465929031372, Generator Loss: 0.9133043885231018\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.4952137768268585, Generator Loss: 1.0745129585266113\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5349704474210739, Generator Loss: 0.9375618696212769\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5393268764019012, Generator Loss: 1.0145976543426514\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.5235391855239868, Generator Loss: 0.9329394102096558\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.5637159645557404, Generator Loss: 1.047060251235962\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.5274678468704224, Generator Loss: 0.9960709810256958\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5314463675022125, Generator Loss: 0.9794835448265076\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5554287880659103, Generator Loss: 0.985584020614624\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5148272216320038, Generator Loss: 0.956841230392456\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5251785963773727, Generator Loss: 0.9696638584136963\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.5393705070018768, Generator Loss: 0.9835214018821716\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.5171289294958115, Generator Loss: 0.99925297498703\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5208522975444794, Generator Loss: 0.9649561047554016\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.5328848659992218, Generator Loss: 1.0173912048339844\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.5166992843151093, Generator Loss: 0.954807698726654\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5401048809289932, Generator Loss: 0.9742423295974731\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5143698751926422, Generator Loss: 0.9067742824554443\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.5134006142616272, Generator Loss: 0.9799483418464661\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.5794023424386978, Generator Loss: 0.908270537853241\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5937460064888, Generator Loss: 1.0400030612945557\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5490396469831467, Generator Loss: 0.9389889240264893\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5198622643947601, Generator Loss: 0.8722407817840576\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5287503153085709, Generator Loss: 1.0593838691711426\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.545574814081192, Generator Loss: 0.9318981170654297\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5407834947109222, Generator Loss: 0.8756639957427979\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5820787847042084, Generator Loss: 0.8529034852981567\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.547695204615593, Generator Loss: 0.9077233672142029\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5454511493444443, Generator Loss: 0.9461476802825928\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5671045184135437, Generator Loss: 0.9176416993141174\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5552145838737488, Generator Loss: 0.8973859548568726\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5592881143093109, Generator Loss: 0.8879032135009766\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5651502013206482, Generator Loss: 0.8282874822616577\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5436201840639114, Generator Loss: 0.9394001960754395\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5410163104534149, Generator Loss: 0.9161521196365356\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5607388317584991, Generator Loss: 0.9295110106468201\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5411068350076675, Generator Loss: 0.9024878740310669\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5116457045078278, Generator Loss: 0.8609861135482788\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5439566373825073, Generator Loss: 0.8892121315002441\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.554497167468071, Generator Loss: 0.9168028235435486\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.5391560196876526, Generator Loss: 0.9085445404052734\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5842254161834717, Generator Loss: 0.9308344125747681\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5448180437088013, Generator Loss: 0.8865010738372803\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5251318216323853, Generator Loss: 0.8472114205360413\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.6031585335731506, Generator Loss: 0.9409640431404114\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.6006691157817841, Generator Loss: 0.8669201135635376\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.5799580514431, Generator Loss: 0.9563686847686768\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5758935958147049, Generator Loss: 0.8364591598510742\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5757054686546326, Generator Loss: 0.8870872259140015\n",
            "8/8 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [04:31<02:20, 20.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7143576145172119, Generator Loss: 0.7187172174453735\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6889289021492004, Generator Loss: 0.7168617248535156\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6622063517570496, Generator Loss: 0.7256211638450623\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6426568925380707, Generator Loss: 0.7288831472396851\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6311065554618835, Generator Loss: 0.7186967730522156\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6096993684768677, Generator Loss: 0.740536093711853\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.5864028632640839, Generator Loss: 0.7535903453826904\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.5730558484792709, Generator Loss: 0.7664671540260315\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.5508921444416046, Generator Loss: 0.7859814167022705\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.5395655632019043, Generator Loss: 0.7859050035476685\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.5354176312685013, Generator Loss: 0.8086761832237244\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.5370392352342606, Generator Loss: 0.7941380739212036\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.524348184466362, Generator Loss: 0.8524306416511536\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.495981901884079, Generator Loss: 0.8926385641098022\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.46611928939819336, Generator Loss: 0.8843257427215576\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.4578495919704437, Generator Loss: 0.9593884348869324\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.4423774778842926, Generator Loss: 0.9219045639038086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.4823944568634033, Generator Loss: 0.9809247255325317\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.40594659745693207, Generator Loss: 0.971135139465332\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.4209708869457245, Generator Loss: 1.052203893661499\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.41818350553512573, Generator Loss: 1.0482499599456787\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.4525955468416214, Generator Loss: 1.0916101932525635\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.4094627946615219, Generator Loss: 1.144456386566162\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.41341620683670044, Generator Loss: 1.1510850191116333\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.41835248470306396, Generator Loss: 1.1638340950012207\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.3982146829366684, Generator Loss: 1.1897437572479248\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.3652886152267456, Generator Loss: 1.1838054656982422\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.3813488185405731, Generator Loss: 1.2285754680633545\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.3909309208393097, Generator Loss: 1.2845373153686523\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.3611004948616028, Generator Loss: 1.314147710800171\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.3574916869401932, Generator Loss: 1.3577042818069458\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.3386751413345337, Generator Loss: 1.2691848278045654\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.3230350837111473, Generator Loss: 1.372089147567749\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.3280109763145447, Generator Loss: 1.3558799028396606\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.32630641758441925, Generator Loss: 1.4036716222763062\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.3283717855811119, Generator Loss: 1.4450573921203613\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.300310343503952, Generator Loss: 1.443291425704956\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.3264381065964699, Generator Loss: 1.4819315671920776\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.3146185129880905, Generator Loss: 1.423171043395996\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.29164377599954605, Generator Loss: 1.5268317461013794\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.34960370510816574, Generator Loss: 1.4829158782958984\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.3398782014846802, Generator Loss: 1.608046531677246\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.33272936940193176, Generator Loss: 1.4994795322418213\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.3124231621623039, Generator Loss: 1.5000526905059814\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.3251589387655258, Generator Loss: 1.5745116472244263\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.31184688210487366, Generator Loss: 1.7600739002227783\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.30848269164562225, Generator Loss: 1.5836818218231201\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.27824486792087555, Generator Loss: 1.5767595767974854\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.29817522317171097, Generator Loss: 1.5904781818389893\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.30791789293289185, Generator Loss: 1.525860071182251\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.3159688115119934, Generator Loss: 1.6040468215942383\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.3831646591424942, Generator Loss: 1.7471485137939453\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.3028430789709091, Generator Loss: 1.5601634979248047\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.3405817896127701, Generator Loss: 1.6370353698730469\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.37989452481269836, Generator Loss: 1.5597670078277588\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.34905100613832474, Generator Loss: 1.6721186637878418\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.3387530595064163, Generator Loss: 1.552604079246521\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.30856987833976746, Generator Loss: 1.5234508514404297\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.33195915818214417, Generator Loss: 1.536553144454956\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.34803107380867004, Generator Loss: 1.6057584285736084\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.32802021503448486, Generator Loss: 1.5296622514724731\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.4007064774632454, Generator Loss: 1.4889812469482422\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.36188559979200363, Generator Loss: 1.5469650030136108\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.32927657663822174, Generator Loss: 1.5587331056594849\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.32648754119873047, Generator Loss: 1.5072466135025024\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.34082038700580597, Generator Loss: 1.4845619201660156\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.3715461269021034, Generator Loss: 1.5075862407684326\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.35449062287807465, Generator Loss: 1.6341001987457275\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.3814955800771713, Generator Loss: 1.5677974224090576\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.3643482029438019, Generator Loss: 1.326974868774414\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.3600655198097229, Generator Loss: 1.5061508417129517\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.36304323375225067, Generator Loss: 1.5097932815551758\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.33236949145793915, Generator Loss: 1.471662998199463\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.3425506204366684, Generator Loss: 1.5657858848571777\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.3691370412707329, Generator Loss: 1.643754482269287\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.3730883225798607, Generator Loss: 1.5445916652679443\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.35965006798505783, Generator Loss: 1.6292294263839722\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.3733574450016022, Generator Loss: 1.4723563194274902\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.319157138466835, Generator Loss: 1.4657353162765503\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.3675190359354019, Generator Loss: 1.3729660511016846\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.32071851193904877, Generator Loss: 1.4168981313705444\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.3412020578980446, Generator Loss: 1.4357951879501343\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.35960833728313446, Generator Loss: 1.5139522552490234\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.32182011008262634, Generator Loss: 1.4735910892486572\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.3844777047634125, Generator Loss: 1.3326964378356934\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.33866389095783234, Generator Loss: 1.5542595386505127\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.3635762259364128, Generator Loss: 1.4829411506652832\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.3037825673818588, Generator Loss: 1.459928035736084\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.29632142186164856, Generator Loss: 1.5109529495239258\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.3729935437440872, Generator Loss: 1.462209701538086\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.3582713380455971, Generator Loss: 1.4562270641326904\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.35721616446971893, Generator Loss: 1.6948637962341309\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.3910711705684662, Generator Loss: 1.6144688129425049\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.3828413411974907, Generator Loss: 1.460230827331543\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.3694700598716736, Generator Loss: 1.3990790843963623\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.3179992660880089, Generator Loss: 1.3319885730743408\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.33707521855831146, Generator Loss: 1.4793992042541504\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.3943384289741516, Generator Loss: 1.4388387203216553\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.36804474890232086, Generator Loss: 1.4373879432678223\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.3635703846812248, Generator Loss: 1.4565317630767822\n",
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [04:51<01:58, 19.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7063893675804138, Generator Loss: 0.6954792141914368\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6807837784290314, Generator Loss: 0.6869100332260132\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6611620485782623, Generator Loss: 0.677339494228363\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6462779343128204, Generator Loss: 0.6900091767311096\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6246996521949768, Generator Loss: 0.6846215724945068\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.619914323091507, Generator Loss: 0.6970564126968384\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.602718859910965, Generator Loss: 0.693622350692749\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.5950393378734589, Generator Loss: 0.7000540494918823\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.5843339115381241, Generator Loss: 0.7172532677650452\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.551706850528717, Generator Loss: 0.735673189163208\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.5549953877925873, Generator Loss: 0.7401160001754761\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.5110058784484863, Generator Loss: 0.795656144618988\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.5390204191207886, Generator Loss: 0.7709430456161499\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.5303597003221512, Generator Loss: 0.8316913843154907\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.5242634564638138, Generator Loss: 0.8406887650489807\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.5104004293680191, Generator Loss: 0.8665435910224915\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.5030916631221771, Generator Loss: 0.8756552338600159\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.4860234558582306, Generator Loss: 0.883894145488739\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.4947955757379532, Generator Loss: 0.9208595156669617\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.4921573996543884, Generator Loss: 0.9933203458786011\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.4806273877620697, Generator Loss: 0.9204623103141785\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.47687071561813354, Generator Loss: 0.9865806102752686\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.4510318338871002, Generator Loss: 1.0103211402893066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.43488195538520813, Generator Loss: 0.9893680810928345\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.40145261585712433, Generator Loss: 1.0089138746261597\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.46652114391326904, Generator Loss: 1.0952203273773193\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.4705282896757126, Generator Loss: 1.0528086423873901\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.43985143303871155, Generator Loss: 1.090790033340454\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.48396483063697815, Generator Loss: 1.1260666847229004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.4744980037212372, Generator Loss: 1.1704740524291992\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.4146713316440582, Generator Loss: 1.2097378969192505\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.43615037202835083, Generator Loss: 1.2157703638076782\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.4314562976360321, Generator Loss: 1.0869264602661133\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.4164023697376251, Generator Loss: 1.113054633140564\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.45132550597190857, Generator Loss: 1.2514907121658325\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.4259151816368103, Generator Loss: 1.2766867876052856\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.44706301391124725, Generator Loss: 1.290924310684204\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.41330163180828094, Generator Loss: 1.2708121538162231\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.41793718934059143, Generator Loss: 1.2775688171386719\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.41186119616031647, Generator Loss: 1.288166880607605\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.36902014911174774, Generator Loss: 1.4241554737091064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.3974398374557495, Generator Loss: 1.2842258214950562\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.38300612568855286, Generator Loss: 1.3264086246490479\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.36310744285583496, Generator Loss: 1.3487255573272705\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.4381987452507019, Generator Loss: 1.3190186023712158\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.4032977968454361, Generator Loss: 1.460157871246338\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.41099226474761963, Generator Loss: 1.3617405891418457\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.3856029212474823, Generator Loss: 1.42577064037323\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.43900126218795776, Generator Loss: 1.4247498512268066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.3763394206762314, Generator Loss: 1.441751480102539\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.419486328959465, Generator Loss: 1.3335449695587158\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.3930438160896301, Generator Loss: 1.519261121749878\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.40632399916648865, Generator Loss: 1.3240211009979248\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.38949593901634216, Generator Loss: 1.425154209136963\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.45075494050979614, Generator Loss: 1.426877737045288\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.41513460874557495, Generator Loss: 1.5957932472229004\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.35813112556934357, Generator Loss: 1.3215358257293701\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.42154061794281006, Generator Loss: 1.4389777183532715\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.39878106117248535, Generator Loss: 1.501477599143982\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.4313330054283142, Generator Loss: 1.3988850116729736\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.41402533650398254, Generator Loss: 1.3245577812194824\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.39880822598934174, Generator Loss: 1.4231288433074951\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.4423947036266327, Generator Loss: 1.4114441871643066\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.4143015295267105, Generator Loss: 1.4929605722427368\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.40093713998794556, Generator Loss: 1.359546184539795\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.45760640501976013, Generator Loss: 1.3671174049377441\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.4189864695072174, Generator Loss: 1.3707733154296875\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.4417785406112671, Generator Loss: 1.2836958169937134\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.4314805269241333, Generator Loss: 1.3107160329818726\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.42085668444633484, Generator Loss: 1.2907519340515137\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.41957463324069977, Generator Loss: 1.3604166507720947\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.4253464937210083, Generator Loss: 1.2555938959121704\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.4861435145139694, Generator Loss: 1.2096917629241943\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.4896150529384613, Generator Loss: 1.239788293838501\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.41772139072418213, Generator Loss: 1.1525914669036865\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.4665660858154297, Generator Loss: 1.2998194694519043\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.4563106596469879, Generator Loss: 1.1728421449661255\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.4704092741012573, Generator Loss: 1.3255667686462402\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.4834775924682617, Generator Loss: 1.1255968809127808\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.4561125338077545, Generator Loss: 1.2954728603363037\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.4715760052204132, Generator Loss: 1.422098159790039\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.4789270907640457, Generator Loss: 1.266507863998413\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.4870258569717407, Generator Loss: 1.2593023777008057\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.4602580815553665, Generator Loss: 1.1606115102767944\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.4793188273906708, Generator Loss: 1.1824651956558228\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.4249667525291443, Generator Loss: 1.289621114730835\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.4627276062965393, Generator Loss: 1.1185170412063599\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.45283380150794983, Generator Loss: 1.164247751235962\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.4128062129020691, Generator Loss: 1.226459264755249\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.4449475407600403, Generator Loss: 1.170806884765625\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.4519294798374176, Generator Loss: 1.2759170532226562\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.4196898937225342, Generator Loss: 1.158433198928833\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.47296878695487976, Generator Loss: 1.2298341989517212\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.46690814197063446, Generator Loss: 1.2000541687011719\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.448336660861969, Generator Loss: 1.2338765859603882\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.429716557264328, Generator Loss: 1.2288405895233154\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.40946777164936066, Generator Loss: 1.087020993232727\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.4304697662591934, Generator Loss: 1.036246657371521\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.441950261592865, Generator Loss: 1.0542843341827393\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.46131426095962524, Generator Loss: 1.1635658740997314\n",
            "8/8 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [05:11<01:39, 19.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7081038057804108, Generator Loss: 0.6724523305892944\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6817581057548523, Generator Loss: 0.6653426289558411\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.664578914642334, Generator Loss: 0.652251124382019\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6595421731472015, Generator Loss: 0.6499894261360168\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6564977765083313, Generator Loss: 0.6447469592094421\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6560139060020447, Generator Loss: 0.6355259418487549\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6439167261123657, Generator Loss: 0.6440253257751465\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6472115814685822, Generator Loss: 0.6400861740112305\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6439589560031891, Generator Loss: 0.6412625312805176\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6367465257644653, Generator Loss: 0.6295866966247559\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6431333720684052, Generator Loss: 0.6331921815872192\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.648842453956604, Generator Loss: 0.6362156867980957\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6492286622524261, Generator Loss: 0.6393585205078125\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6370127201080322, Generator Loss: 0.6435707807540894\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.646293580532074, Generator Loss: 0.6494458317756653\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6471188366413116, Generator Loss: 0.6515370011329651\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.6318257749080658, Generator Loss: 0.6628313064575195\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6351423859596252, Generator Loss: 0.6511814594268799\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6214480698108673, Generator Loss: 0.6844514608383179\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.6529927253723145, Generator Loss: 0.7024691104888916\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6163379848003387, Generator Loss: 0.70009446144104\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.6050755679607391, Generator Loss: 0.7201740741729736\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.6372396647930145, Generator Loss: 0.7314804792404175\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.629277765750885, Generator Loss: 0.696603000164032\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.6304801106452942, Generator Loss: 0.7144511938095093\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.6160954236984253, Generator Loss: 0.759722113609314\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.6124602854251862, Generator Loss: 0.7690749168395996\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.6052544116973877, Generator Loss: 0.7194401621818542\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.6270555257797241, Generator Loss: 0.7604604959487915\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.6087684631347656, Generator Loss: 0.7428069114685059\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.6080630421638489, Generator Loss: 0.7762783765792847\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.6020563840866089, Generator Loss: 0.7386342287063599\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5956789553165436, Generator Loss: 0.7936169505119324\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.5880873203277588, Generator Loss: 0.8068978190422058\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.626069188117981, Generator Loss: 0.7988320589065552\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5926633477210999, Generator Loss: 0.8108557462692261\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.5846273303031921, Generator Loss: 0.7991747856140137\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5845470130443573, Generator Loss: 0.8429477214813232\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.592269778251648, Generator Loss: 0.8096209764480591\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.5806199908256531, Generator Loss: 0.8364353179931641\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5872793793678284, Generator Loss: 0.8508813381195068\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.58523890376091, Generator Loss: 0.7882541418075562\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5937652587890625, Generator Loss: 0.8400256633758545\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.6026709079742432, Generator Loss: 0.8462450504302979\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.592763751745224, Generator Loss: 0.8292481899261475\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.587769478559494, Generator Loss: 0.8132575750350952\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.6038178503513336, Generator Loss: 0.8280571699142456\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.588684618473053, Generator Loss: 0.8039400577545166\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5724886655807495, Generator Loss: 0.7925336360931396\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5923259556293488, Generator Loss: 0.8809242248535156\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5830627381801605, Generator Loss: 0.8216829299926758\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.5789903700351715, Generator Loss: 0.8509525060653687\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.624475508928299, Generator Loss: 0.8398348689079285\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5667887032032013, Generator Loss: 0.894690990447998\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5750532150268555, Generator Loss: 0.8044199347496033\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.6140940189361572, Generator Loss: 0.840755820274353\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.5601707696914673, Generator Loss: 0.9131876230239868\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.551481157541275, Generator Loss: 0.8665672540664673\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5890671610832214, Generator Loss: 0.8525786399841309\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5658680498600006, Generator Loss: 0.856370747089386\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.578222393989563, Generator Loss: 0.873988151550293\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5760025680065155, Generator Loss: 0.8209103941917419\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.5962197482585907, Generator Loss: 0.9551979899406433\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.5820052921772003, Generator Loss: 0.8473877310752869\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5856184363365173, Generator Loss: 0.8275065422058105\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.5817435383796692, Generator Loss: 0.8492813110351562\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.595505952835083, Generator Loss: 0.8493854999542236\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5875781774520874, Generator Loss: 0.8887444734573364\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5905354022979736, Generator Loss: 0.8674638867378235\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.5622502863407135, Generator Loss: 0.8463050127029419\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.5680201351642609, Generator Loss: 0.8816060423851013\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.593328446149826, Generator Loss: 0.8789479732513428\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5633711814880371, Generator Loss: 0.8542686700820923\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5743240118026733, Generator Loss: 0.8220983147621155\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5843064188957214, Generator Loss: 0.8550236225128174\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.6048258244991302, Generator Loss: 0.8632137775421143\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5863633751869202, Generator Loss: 0.8467150926589966\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5743302404880524, Generator Loss: 0.8626054525375366\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5938422083854675, Generator Loss: 0.8861976861953735\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5911444127559662, Generator Loss: 0.8727545738220215\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5768212378025055, Generator Loss: 0.8293876051902771\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5754432082176208, Generator Loss: 0.8536937236785889\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.6005493700504303, Generator Loss: 0.8289768099784851\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5869136154651642, Generator Loss: 0.8754526376724243\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5631536245346069, Generator Loss: 0.8409940004348755\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5878523886203766, Generator Loss: 0.8595661520957947\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5665766596794128, Generator Loss: 0.844507098197937\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5798563063144684, Generator Loss: 0.8292027711868286\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.580917626619339, Generator Loss: 0.8357272148132324\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5518575310707092, Generator Loss: 0.8513724207878113\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5822613835334778, Generator Loss: 0.8784380555152893\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.5513358116149902, Generator Loss: 0.8318029642105103\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5846633017063141, Generator Loss: 0.8710355758666992\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5630998313426971, Generator Loss: 0.846767008304596\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5580770373344421, Generator Loss: 0.8578869700431824\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5757066011428833, Generator Loss: 0.8509013056755066\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5405299067497253, Generator Loss: 0.8722980618476868\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.5818095207214355, Generator Loss: 0.8638908863067627\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5596378147602081, Generator Loss: 0.8965528011322021\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5488812327384949, Generator Loss: 0.8665976524353027\n",
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [05:31<01:19, 19.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7138379514217377, Generator Loss: 0.6859035491943359\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6952183842658997, Generator Loss: 0.6680558919906616\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6833154559135437, Generator Loss: 0.6627829074859619\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6705806851387024, Generator Loss: 0.6503173112869263\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.659981369972229, Generator Loss: 0.6489885449409485\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6518312096595764, Generator Loss: 0.6417309045791626\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6446416079998016, Generator Loss: 0.6441912651062012\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6437391042709351, Generator Loss: 0.6458073258399963\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6426452398300171, Generator Loss: 0.6487979888916016\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6393527388572693, Generator Loss: 0.6527009010314941\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6503918766975403, Generator Loss: 0.6359046101570129\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6333373188972473, Generator Loss: 0.6354303956031799\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6465034782886505, Generator Loss: 0.621901273727417\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.646842896938324, Generator Loss: 0.6533026099205017\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6408424377441406, Generator Loss: 0.654682993888855\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6533569097518921, Generator Loss: 0.6475176811218262\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.6448249816894531, Generator Loss: 0.6421549916267395\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6334779858589172, Generator Loss: 0.6641870737075806\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6453194618225098, Generator Loss: 0.6597096920013428\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.62982177734375, Generator Loss: 0.6719521284103394\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6305896639823914, Generator Loss: 0.6589750647544861\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.6389473974704742, Generator Loss: 0.6816278100013733\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.6218120157718658, Generator Loss: 0.6890462636947632\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.6200564205646515, Generator Loss: 0.6985218524932861\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.6148779690265656, Generator Loss: 0.6923521161079407\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.6239016056060791, Generator Loss: 0.6923930644989014\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.6331465244293213, Generator Loss: 0.7423962950706482\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.6122801005840302, Generator Loss: 0.7307966947555542\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.610554575920105, Generator Loss: 0.7389487028121948\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.6103399097919464, Generator Loss: 0.7608745694160461\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.604329913854599, Generator Loss: 0.7542284727096558\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.614935964345932, Generator Loss: 0.7719759941101074\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.6236927211284637, Generator Loss: 0.7631242275238037\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.6064012944698334, Generator Loss: 0.7764544486999512\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.6042801439762115, Generator Loss: 0.7614708542823792\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.6202213168144226, Generator Loss: 0.75151526927948\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.6212577521800995, Generator Loss: 0.7909088134765625\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5851791203022003, Generator Loss: 0.77540123462677\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.6168469488620758, Generator Loss: 0.7688160538673401\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.6003746390342712, Generator Loss: 0.7861751317977905\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5875095427036285, Generator Loss: 0.7876615524291992\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.6058580577373505, Generator Loss: 0.7660911083221436\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.6013549864292145, Generator Loss: 0.8138718605041504\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.5954408645629883, Generator Loss: 0.8075169324874878\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.6130749881267548, Generator Loss: 0.7952514886856079\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.6090139746665955, Generator Loss: 0.7777506113052368\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.5868061184883118, Generator Loss: 0.8237168788909912\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5862284302711487, Generator Loss: 0.8153815269470215\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5875066220760345, Generator Loss: 0.8026608228683472\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5934224128723145, Generator Loss: 0.8269681930541992\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5963502526283264, Generator Loss: 0.7849266529083252\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.5936475396156311, Generator Loss: 0.8389081358909607\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.5801611542701721, Generator Loss: 0.7954927682876587\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5899452567100525, Generator Loss: 0.7968371510505676\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5874607264995575, Generator Loss: 0.8359508514404297\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.5889592170715332, Generator Loss: 0.8271592259407043\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.5838882327079773, Generator Loss: 0.8091912269592285\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.6119466423988342, Generator Loss: 0.835461437702179\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5569281280040741, Generator Loss: 0.7850952744483948\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5887496173381805, Generator Loss: 0.8095424175262451\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5631283223628998, Generator Loss: 0.8061951398849487\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5646117925643921, Generator Loss: 0.8220675587654114\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.6149266958236694, Generator Loss: 0.8176923990249634\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.5592350363731384, Generator Loss: 0.824664831161499\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.576909214258194, Generator Loss: 0.8408653140068054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.6065782308578491, Generator Loss: 0.8225439190864563\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.5634038746356964, Generator Loss: 0.8165050745010376\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5705336928367615, Generator Loss: 0.8438915610313416\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5734221935272217, Generator Loss: 0.8170632123947144\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.5863416790962219, Generator Loss: 0.8151065707206726\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.5746073126792908, Generator Loss: 0.8195014595985413\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5949811041355133, Generator Loss: 0.8557175397872925\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.580683022737503, Generator Loss: 0.8258106112480164\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5662927627563477, Generator Loss: 0.8155326843261719\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.5859248638153076, Generator Loss: 0.8610678911209106\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5624532997608185, Generator Loss: 0.8509718179702759\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.5770560204982758, Generator Loss: 0.839523196220398\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5675328969955444, Generator Loss: 0.8398640751838684\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5891581177711487, Generator Loss: 0.8517684936523438\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5560181438922882, Generator Loss: 0.8839067220687866\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5590079724788666, Generator Loss: 0.818308413028717\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5794899165630341, Generator Loss: 0.8460208773612976\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5546852648258209, Generator Loss: 0.8647737503051758\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5855486989021301, Generator Loss: 0.8908730149269104\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5842016935348511, Generator Loss: 0.8246586918830872\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5848450660705566, Generator Loss: 0.8683264255523682\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5906439423561096, Generator Loss: 0.8447001576423645\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5742846727371216, Generator Loss: 0.8451764583587646\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5877781510353088, Generator Loss: 0.8753789663314819\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5625628232955933, Generator Loss: 0.8472495675086975\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5734776556491852, Generator Loss: 0.8412458300590515\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.5594577789306641, Generator Loss: 0.8563185930252075\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5609964728355408, Generator Loss: 0.8775720596313477\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.578709214925766, Generator Loss: 0.8727090358734131\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.5503073632717133, Generator Loss: 0.874975323677063\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5483301877975464, Generator Loss: 0.8439345955848694\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5523444712162018, Generator Loss: 0.8745602369308472\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.569031834602356, Generator Loss: 0.8512471318244934\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5533890128135681, Generator Loss: 0.8874554634094238\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.57447150349617, Generator Loss: 0.8482871055603027\n",
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [05:51<00:59, 19.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.6846393942832947, Generator Loss: 0.6720173358917236\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6692387461662292, Generator Loss: 0.657596230506897\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6578434407711029, Generator Loss: 0.6514161229133606\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6513603329658508, Generator Loss: 0.6444267630577087\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6448071002960205, Generator Loss: 0.6381716132164001\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6408974528312683, Generator Loss: 0.6463693976402283\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6348978281021118, Generator Loss: 0.6381344199180603\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6186753958463669, Generator Loss: 0.6514793634414673\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6248782575130463, Generator Loss: 0.6514887809753418\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6306374371051788, Generator Loss: 0.6495834589004517\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6307742893695831, Generator Loss: 0.6628117561340332\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6145405173301697, Generator Loss: 0.6608389616012573\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6071658581495285, Generator Loss: 0.658332109451294\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6104079484939575, Generator Loss: 0.6982641220092773\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6038210541009903, Generator Loss: 0.6939319968223572\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.636204332113266, Generator Loss: 0.6864058375358582\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.5942398458719254, Generator Loss: 0.6986876726150513\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.5960046648979187, Generator Loss: 0.7171211838722229\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.5944547951221466, Generator Loss: 0.7103794813156128\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.569158524274826, Generator Loss: 0.743703305721283\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.584867998957634, Generator Loss: 0.7329355478286743\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.6143908649682999, Generator Loss: 0.7684330940246582\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.5675895363092422, Generator Loss: 0.7177216410636902\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.5982213914394379, Generator Loss: 0.7302781343460083\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.5800598710775375, Generator Loss: 0.7850828170776367\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.5778965801000595, Generator Loss: 0.7456632852554321\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.5909363925457001, Generator Loss: 0.7389471530914307\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.5838652849197388, Generator Loss: 0.7547725439071655\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.5856340080499649, Generator Loss: 0.8269264698028564\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.5693735182285309, Generator Loss: 0.8322252035140991\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.5706245601177216, Generator Loss: 0.775463342666626\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.556708574295044, Generator Loss: 0.8683863282203674\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.5933192372322083, Generator Loss: 0.8577463626861572\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.5617557168006897, Generator Loss: 0.8176722526550293\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.5526157915592194, Generator Loss: 0.8614884614944458\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5524799674749374, Generator Loss: 0.806220293045044\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.5406307131052017, Generator Loss: 0.9433791637420654\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.5379592180252075, Generator Loss: 0.857824444770813\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.578047901391983, Generator Loss: 0.923137366771698\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.546325147151947, Generator Loss: 0.9567793011665344\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.5225083529949188, Generator Loss: 0.8766089081764221\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.5465180575847626, Generator Loss: 0.9017345905303955\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5767453610897064, Generator Loss: 0.8882120251655579\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.5481926053762436, Generator Loss: 0.9383597373962402\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.5819733887910843, Generator Loss: 1.0022449493408203\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.54123455286026, Generator Loss: 1.001549482345581\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.5863746404647827, Generator Loss: 0.9795339107513428\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.5600576102733612, Generator Loss: 0.899884045124054\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5260880291461945, Generator Loss: 0.902463436126709\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5614650845527649, Generator Loss: 0.8984411954879761\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.5225483179092407, Generator Loss: 0.9531835317611694\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.5706122666597366, Generator Loss: 0.9496043920516968\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.5637717545032501, Generator Loss: 0.9778266549110413\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.5692838430404663, Generator Loss: 0.9191666841506958\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.5710644125938416, Generator Loss: 0.9794801473617554\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.5446660816669464, Generator Loss: 0.9008321762084961\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.5522483736276627, Generator Loss: 0.9446079730987549\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.565703809261322, Generator Loss: 0.866569459438324\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.5346535742282867, Generator Loss: 0.9085519909858704\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.5384712070226669, Generator Loss: 0.925458550453186\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.5639471709728241, Generator Loss: 0.894150972366333\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.5295937061309814, Generator Loss: 0.9570920467376709\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.5851519703865051, Generator Loss: 0.9494138956069946\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.5792518258094788, Generator Loss: 0.9700967669487\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5518421530723572, Generator Loss: 1.0797772407531738\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.5667123794555664, Generator Loss: 0.9580216407775879\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.5587884783744812, Generator Loss: 1.038079857826233\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.5466608107089996, Generator Loss: 1.0004335641860962\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5329270660877228, Generator Loss: 0.9997925162315369\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.579257607460022, Generator Loss: 0.9680892825126648\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.5275284051895142, Generator Loss: 0.870081901550293\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.578958660364151, Generator Loss: 0.9271648526191711\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.5560664534568787, Generator Loss: 0.8899620175361633\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.6059942841529846, Generator Loss: 1.016385793685913\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.554924950003624, Generator Loss: 0.957897424697876\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.5538902282714844, Generator Loss: 0.9703102111816406\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.542940765619278, Generator Loss: 0.9282914996147156\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.5487828552722931, Generator Loss: 0.9159853458404541\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.5500188767910004, Generator Loss: 0.9378399848937988\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.5500730872154236, Generator Loss: 0.92973792552948\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.5528032183647156, Generator Loss: 0.931667685508728\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.5676237940788269, Generator Loss: 0.9113637208938599\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.5680844932794571, Generator Loss: 0.9176700115203857\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5976860225200653, Generator Loss: 0.9362531304359436\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.5463092029094696, Generator Loss: 0.8378152847290039\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.5818266272544861, Generator Loss: 0.8903328776359558\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.5600135028362274, Generator Loss: 0.8702243566513062\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.5629090368747711, Generator Loss: 0.9449697732925415\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.5906080305576324, Generator Loss: 0.8390278816223145\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.5395458340644836, Generator Loss: 0.8851044178009033\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.5746786892414093, Generator Loss: 0.8200576305389404\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.5694916844367981, Generator Loss: 0.863563060760498\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.5923040807247162, Generator Loss: 0.8744652271270752\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.5945377349853516, Generator Loss: 0.8382854461669922\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.568539172410965, Generator Loss: 0.8851776123046875\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.5688819885253906, Generator Loss: 0.8503595590591431\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.5624938011169434, Generator Loss: 0.8615502119064331\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.5669116973876953, Generator Loss: 0.8629282116889954\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.5611416101455688, Generator Loss: 0.8462168574333191\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.5522767007350922, Generator Loss: 0.8656238317489624\n",
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [06:11<00:40, 20.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7308467328548431, Generator Loss: 0.7317431569099426\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.7111347019672394, Generator Loss: 0.7138060331344604\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6916098296642303, Generator Loss: 0.7078460454940796\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6855323910713196, Generator Loss: 0.7019884586334229\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6712838709354401, Generator Loss: 0.7057620286941528\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6609216034412384, Generator Loss: 0.6991657614707947\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6461048722267151, Generator Loss: 0.6827796697616577\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.6328116059303284, Generator Loss: 0.6979754567146301\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.6265482604503632, Generator Loss: 0.6858432292938232\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.6279001533985138, Generator Loss: 0.6844753623008728\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.6159400045871735, Generator Loss: 0.6861883401870728\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.6142536103725433, Generator Loss: 0.6729586124420166\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.6191992163658142, Generator Loss: 0.6824136972427368\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.6241750419139862, Generator Loss: 0.6612219214439392\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.6200949251651764, Generator Loss: 0.6512899398803711\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.6154994666576385, Generator Loss: 0.6756386160850525\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.6116902083158493, Generator Loss: 0.6677781343460083\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.6324917674064636, Generator Loss: 0.6406964063644409\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.6475860178470612, Generator Loss: 0.6743984222412109\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.6200897693634033, Generator Loss: 0.7008998394012451\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.6546840369701385, Generator Loss: 0.6602834463119507\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.6500103175640106, Generator Loss: 0.6857728958129883\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.6181674599647522, Generator Loss: 0.6646474003791809\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.6528104543685913, Generator Loss: 0.6901823282241821\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.6575774252414703, Generator Loss: 0.6843447685241699\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.6263538599014282, Generator Loss: 0.6652595400810242\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.6282312273979187, Generator Loss: 0.7164515256881714\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.6356269717216492, Generator Loss: 0.7132500410079956\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.6062317788600922, Generator Loss: 0.7179962396621704\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.628660261631012, Generator Loss: 0.7276186347007751\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.6345773339271545, Generator Loss: 0.7433589696884155\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.6330834031105042, Generator Loss: 0.7324536442756653\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.6197938024997711, Generator Loss: 0.7000548243522644\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.6369156241416931, Generator Loss: 0.7473176717758179\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.6167093515396118, Generator Loss: 0.7494040727615356\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.5901817083358765, Generator Loss: 0.7484886646270752\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.6310805678367615, Generator Loss: 0.7536077499389648\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.6389720439910889, Generator Loss: 0.7851237058639526\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.6026611030101776, Generator Loss: 0.7550795674324036\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.6166406869888306, Generator Loss: 0.7910968065261841\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.6226334571838379, Generator Loss: 0.7590636610984802\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.6001637578010559, Generator Loss: 0.790329098701477\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.5922503471374512, Generator Loss: 0.7673572301864624\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.6032650172710419, Generator Loss: 0.7999007105827332\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.6177074909210205, Generator Loss: 0.7821060419082642\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.6106952130794525, Generator Loss: 0.8157842755317688\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.6271206438541412, Generator Loss: 0.7969164252281189\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.6072278320789337, Generator Loss: 0.7870562672615051\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.5826006233692169, Generator Loss: 0.7857612371444702\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.5947864055633545, Generator Loss: 0.7978439331054688\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.6177224814891815, Generator Loss: 0.7805860042572021\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.5845407545566559, Generator Loss: 0.7981641292572021\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.5990288853645325, Generator Loss: 0.8249397277832031\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.6096535921096802, Generator Loss: 0.7842072248458862\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.6107657551765442, Generator Loss: 0.7494438886642456\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.6172186732292175, Generator Loss: 0.8010958433151245\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.6274458765983582, Generator Loss: 0.8015624284744263\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.6185310482978821, Generator Loss: 0.793142557144165\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.6193787455558777, Generator Loss: 0.791215181350708\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.6896712779998779, Generator Loss: 0.8195818662643433\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.6570797562599182, Generator Loss: 0.7997051477432251\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.6186503767967224, Generator Loss: 0.7594821453094482\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.6246170103549957, Generator Loss: 0.7853490710258484\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.6243908405303955, Generator Loss: 0.7439846992492676\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.5934832990169525, Generator Loss: 0.7620329856872559\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.6023069024085999, Generator Loss: 0.7598140239715576\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.5957055687904358, Generator Loss: 0.765580415725708\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.6235879957675934, Generator Loss: 0.7940967082977295\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.5923061370849609, Generator Loss: 0.7322572469711304\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.6033734381198883, Generator Loss: 0.801724910736084\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.6052376329898834, Generator Loss: 0.7572953104972839\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.6259936094284058, Generator Loss: 0.774910032749176\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.6388034820556641, Generator Loss: 0.7520118951797485\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.6256257593631744, Generator Loss: 0.8082494735717773\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.615921825170517, Generator Loss: 0.7844871282577515\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.6045464277267456, Generator Loss: 0.7834434509277344\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.6279619038105011, Generator Loss: 0.7873214483261108\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.6419791579246521, Generator Loss: 0.8001140356063843\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.6404213905334473, Generator Loss: 0.7858729362487793\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.6070133447647095, Generator Loss: 0.7530803680419922\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.6433698236942291, Generator Loss: 0.7760797739028931\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.6473953723907471, Generator Loss: 0.7869548797607422\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.6123046875, Generator Loss: 0.7738484144210815\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.6592398285865784, Generator Loss: 0.7594220638275146\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.6608438789844513, Generator Loss: 0.7559249401092529\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.6343382894992828, Generator Loss: 0.7387127876281738\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.6262553930282593, Generator Loss: 0.7453899383544922\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.6134411692619324, Generator Loss: 0.7447817921638489\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.6491726040840149, Generator Loss: 0.7985814809799194\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.6500025987625122, Generator Loss: 0.7644794583320618\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.6042521595954895, Generator Loss: 0.7330545783042908\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.6495431661605835, Generator Loss: 0.7464022636413574\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.6160537600517273, Generator Loss: 0.764777660369873\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.6514537036418915, Generator Loss: 0.7290585041046143\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.6509408950805664, Generator Loss: 0.761757493019104\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.6282426118850708, Generator Loss: 0.7523226141929626\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.6121988892555237, Generator Loss: 0.7335877418518066\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.6452409625053406, Generator Loss: 0.7727985382080078\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.6218680739402771, Generator Loss: 0.7595912218093872\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.6345203518867493, Generator Loss: 0.7549605369567871\n",
            "8/8 [==============================] - 0s 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [06:32<00:20, 20.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 0, Discriminator Loss: 0.7009195685386658, Generator Loss: 0.7171387672424316\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 1, Discriminator Loss: 0.6731048226356506, Generator Loss: 0.7052797079086304\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 2, Discriminator Loss: 0.6573531031608582, Generator Loss: 0.6989258527755737\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 3, Discriminator Loss: 0.6378941237926483, Generator Loss: 0.7011330127716064\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 4, Discriminator Loss: 0.6277550756931305, Generator Loss: 0.702986478805542\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 5, Discriminator Loss: 0.6324021220207214, Generator Loss: 0.7089941501617432\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 6, Discriminator Loss: 0.6122668087482452, Generator Loss: 0.7080792188644409\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 7, Discriminator Loss: 0.5948198288679123, Generator Loss: 0.7208279371261597\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 8, Discriminator Loss: 0.5932054966688156, Generator Loss: 0.7109010219573975\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 9, Discriminator Loss: 0.5834696292877197, Generator Loss: 0.7379967570304871\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 10, Discriminator Loss: 0.5745966285467148, Generator Loss: 0.7582899332046509\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 11, Discriminator Loss: 0.5648619830608368, Generator Loss: 0.7747217416763306\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 12, Discriminator Loss: 0.5660704374313354, Generator Loss: 0.7955673933029175\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 13, Discriminator Loss: 0.5374200195074081, Generator Loss: 0.7912329435348511\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 14, Discriminator Loss: 0.548644483089447, Generator Loss: 0.8646708130836487\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 15, Discriminator Loss: 0.4945039451122284, Generator Loss: 0.8363237380981445\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 16, Discriminator Loss: 0.5487602800130844, Generator Loss: 0.8638728260993958\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 17, Discriminator Loss: 0.534029096364975, Generator Loss: 0.8946866393089294\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 18, Discriminator Loss: 0.5061225891113281, Generator Loss: 0.9002315998077393\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "Epoch: 19, Discriminator Loss: 0.4992194175720215, Generator Loss: 0.8871521949768066\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 20, Discriminator Loss: 0.5241773575544357, Generator Loss: 0.931597113609314\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 21, Discriminator Loss: 0.4598403126001358, Generator Loss: 0.9407268166542053\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 22, Discriminator Loss: 0.46429941058158875, Generator Loss: 0.9600346088409424\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 23, Discriminator Loss: 0.49602241814136505, Generator Loss: 0.9865578413009644\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 24, Discriminator Loss: 0.46410463750362396, Generator Loss: 1.0080159902572632\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 25, Discriminator Loss: 0.49386927485466003, Generator Loss: 1.033379077911377\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 26, Discriminator Loss: 0.4381963610649109, Generator Loss: 1.0433862209320068\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 27, Discriminator Loss: 0.4402024745941162, Generator Loss: 0.9906529188156128\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 28, Discriminator Loss: 0.44804903864860535, Generator Loss: 1.0585291385650635\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 29, Discriminator Loss: 0.47352224588394165, Generator Loss: 1.1475839614868164\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 30, Discriminator Loss: 0.47935202717781067, Generator Loss: 1.1336045265197754\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 31, Discriminator Loss: 0.43539950251579285, Generator Loss: 1.145078420639038\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 32, Discriminator Loss: 0.48261648416519165, Generator Loss: 1.1222484111785889\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 33, Discriminator Loss: 0.43855707347393036, Generator Loss: 1.1178921461105347\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "Epoch: 34, Discriminator Loss: 0.40000393986701965, Generator Loss: 1.1934528350830078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 35, Discriminator Loss: 0.400642067193985, Generator Loss: 1.18800687789917\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 36, Discriminator Loss: 0.4124024510383606, Generator Loss: 1.1194502115249634\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 37, Discriminator Loss: 0.4579467177391052, Generator Loss: 1.2560555934906006\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 38, Discriminator Loss: 0.4170738160610199, Generator Loss: 1.3076366186141968\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 39, Discriminator Loss: 0.4118713140487671, Generator Loss: 1.2970294952392578\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 40, Discriminator Loss: 0.40539152920246124, Generator Loss: 1.229583740234375\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 41, Discriminator Loss: 0.37015368044376373, Generator Loss: 1.3292999267578125\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 42, Discriminator Loss: 0.39205896854400635, Generator Loss: 1.176313042640686\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 43, Discriminator Loss: 0.3911547064781189, Generator Loss: 1.3151006698608398\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 44, Discriminator Loss: 0.41029711067676544, Generator Loss: 1.353317379951477\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 45, Discriminator Loss: 0.4185439944267273, Generator Loss: 1.2491313219070435\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 46, Discriminator Loss: 0.3943237066268921, Generator Loss: 1.427163004875183\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 47, Discriminator Loss: 0.38799892365932465, Generator Loss: 1.2353873252868652\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 48, Discriminator Loss: 0.38412533700466156, Generator Loss: 1.3657952547073364\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 49, Discriminator Loss: 0.42267143726348877, Generator Loss: 1.4234387874603271\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "Epoch: 50, Discriminator Loss: 0.39241644740104675, Generator Loss: 1.3674030303955078\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 51, Discriminator Loss: 0.45521214604377747, Generator Loss: 1.355826735496521\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 52, Discriminator Loss: 0.44708143174648285, Generator Loss: 1.3475921154022217\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "Epoch: 53, Discriminator Loss: 0.40146808326244354, Generator Loss: 1.4111427068710327\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 54, Discriminator Loss: 0.4163084924221039, Generator Loss: 1.391325831413269\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 55, Discriminator Loss: 0.3570675700902939, Generator Loss: 1.3019700050354004\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 56, Discriminator Loss: 0.42288772761821747, Generator Loss: 1.3180842399597168\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 57, Discriminator Loss: 0.4139271229505539, Generator Loss: 1.2911165952682495\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "Epoch: 58, Discriminator Loss: 0.4251596927642822, Generator Loss: 1.3265289068222046\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 59, Discriminator Loss: 0.45192913711071014, Generator Loss: 1.2403556108474731\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 60, Discriminator Loss: 0.4633421301841736, Generator Loss: 1.2251371145248413\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 61, Discriminator Loss: 0.45153018832206726, Generator Loss: 1.3036539554595947\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 62, Discriminator Loss: 0.4511021077632904, Generator Loss: 1.1914341449737549\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 63, Discriminator Loss: 0.41262367367744446, Generator Loss: 1.250246286392212\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 64, Discriminator Loss: 0.4852397292852402, Generator Loss: 1.2418196201324463\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 65, Discriminator Loss: 0.43606601655483246, Generator Loss: 1.2566745281219482\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 66, Discriminator Loss: 0.41654786467552185, Generator Loss: 1.2417945861816406\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 67, Discriminator Loss: 0.4261130690574646, Generator Loss: 1.3314701318740845\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 68, Discriminator Loss: 0.45167645812034607, Generator Loss: 1.2928494215011597\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 69, Discriminator Loss: 0.46576055884361267, Generator Loss: 1.276841402053833\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 70, Discriminator Loss: 0.4627004414796829, Generator Loss: 1.2099621295928955\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 71, Discriminator Loss: 0.5070215463638306, Generator Loss: 1.2384586334228516\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 72, Discriminator Loss: 0.48925769329071045, Generator Loss: 1.1686090230941772\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 73, Discriminator Loss: 0.5072236359119415, Generator Loss: 1.2188103199005127\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 74, Discriminator Loss: 0.47093355655670166, Generator Loss: 1.1075849533081055\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 75, Discriminator Loss: 0.4654189497232437, Generator Loss: 1.082913875579834\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 76, Discriminator Loss: 0.452848881483078, Generator Loss: 1.18345308303833\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 77, Discriminator Loss: 0.4544665366411209, Generator Loss: 1.0786316394805908\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "Epoch: 78, Discriminator Loss: 0.42843496799468994, Generator Loss: 1.169801950454712\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 79, Discriminator Loss: 0.4199403375387192, Generator Loss: 1.099481225013733\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Epoch: 80, Discriminator Loss: 0.47297303378582, Generator Loss: 1.0242524147033691\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 81, Discriminator Loss: 0.4635844826698303, Generator Loss: 1.098031759262085\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 82, Discriminator Loss: 0.43681296706199646, Generator Loss: 1.0736362934112549\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 83, Discriminator Loss: 0.5064514726400375, Generator Loss: 1.1769616603851318\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 84, Discriminator Loss: 0.4981634020805359, Generator Loss: 1.0624338388442993\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 85, Discriminator Loss: 0.487488716840744, Generator Loss: 1.0358920097351074\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 86, Discriminator Loss: 0.4600040763616562, Generator Loss: 1.149884819984436\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 87, Discriminator Loss: 0.4790937304496765, Generator Loss: 0.9880306720733643\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "Epoch: 88, Discriminator Loss: 0.4565373659133911, Generator Loss: 1.1928737163543701\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "Epoch: 89, Discriminator Loss: 0.47402626276016235, Generator Loss: 1.0539706945419312\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 90, Discriminator Loss: 0.45232877135276794, Generator Loss: 0.9653910398483276\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 91, Discriminator Loss: 0.4699515700340271, Generator Loss: 1.0168191194534302\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Epoch: 92, Discriminator Loss: 0.44214561581611633, Generator Loss: 1.0565218925476074\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 93, Discriminator Loss: 0.44492843747138977, Generator Loss: 1.0859721899032593\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 94, Discriminator Loss: 0.4463687837123871, Generator Loss: 1.0103590488433838\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Epoch: 95, Discriminator Loss: 0.48029637336730957, Generator Loss: 1.0078973770141602\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 96, Discriminator Loss: 0.479069247841835, Generator Loss: 0.9894495010375977\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 97, Discriminator Loss: 0.45563970506191254, Generator Loss: 1.1112756729125977\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 98, Discriminator Loss: 0.4535973072052002, Generator Loss: 1.0920770168304443\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Epoch: 99, Discriminator Loss: 0.4504617899656296, Generator Loss: 1.0480496883392334\n",
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [06:54<00:00, 20.71s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_label = []\n",
        "for i in range(20):\n",
        "    gen_label_temp = np.tile(i, data_to_gen)\n",
        "    gen_label.extend(gen_label_temp)\n",
        "\n",
        "gen_label = np.asarray(gen_label, dtype=np.float32)\n",
        "gen_label_encoded = to_categorical(gen_label)\n",
        "\n",
        "gen_data_reshaped = gen_data.reshape(num_of_classes*data_to_gen, data_shape[0])\n",
        "\n",
        "X_train_gan, Y_train_gan = shuffle(gen_data_reshaped,\n",
        "                                   gen_label_encoded,\n",
        "                                   random_state=5)\n",
        "\n",
        "new_x_train = np.concatenate((X_train, X_train_gan), axis=0)\n",
        "new_y_train = np.concatenate((Y_train_encoded, Y_train_gan), axis=0)\n",
        "\n",
        "new_x_train, new_y_train = shuffle(new_x_train, new_y_train, random_state=15)\n",
        "new_x_train_transformed = scaler.fit_transform(new_x_train)"
      ],
      "metadata": {
        "id": "ud4ryMhZgZ-e"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_test_loss_gan =[]\n",
        "all_test_acc_gan = []\n",
        "ganhistory = []\n",
        "\n",
        "for i in tqdm_notebook(range(50)):\n",
        "    seed(i*seed_multiplier)\n",
        "    tf.random.set_seed(i*seed_multiplier)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_shape=(6,), activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(20, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=Adam(0.0002, 0.5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    ganhistorytemp = model.fit(new_x_train_transformed,\n",
        "                    new_y_train,\n",
        "                    epochs=mlp_epochs,\n",
        "                    batch_size=64,\n",
        "                    validation_split=valid_split,\n",
        "                    verbose = 0)\n",
        "    ganhistory.append(ganhistorytemp)\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(X_test_transformed,\n",
        "                                         Y_test_encoded,\n",
        "                                         verbose=0)\n",
        "    print(\"#{} Test acc:\".format(i), test_acc)\n",
        "\n",
        "    all_test_acc_gan.append(test_acc)\n",
        "    all_test_loss_gan.append(test_loss)\n",
        "    del(model)\n",
        "    clear_session()\n",
        "\n",
        "def average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "avr = round(average(all_test_acc_gan),3)\n",
        "print(\"AVERAGE TEST ACCURACY : \",avr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986,
          "referenced_widgets": [
            "bfd15ac3a5174c2e86b52fe102e7ed6c",
            "6ea16f2d1f734cf8b601062408153dc8",
            "4f90b61a9f094082af38a12b55bc4146",
            "fa7f81deab7d45d0a9b4d020b105010a",
            "ad1d92bb374b47bd93e633a79abf26dc",
            "5f702b18c166469ba3e91d079f6c8b91",
            "75006360f65a4acc90014ce055e39ea8",
            "a63469b5f4554ca2b204433e26950e56",
            "397c5e6ad3f14e9c96cfd5b812c69b2c",
            "aaa0c051c0284058815218e60a1f3d0b",
            "9b0f2a3ce656429093fd66051e62bfb8"
          ]
        },
        "id": "AILzj9ipBVRY",
        "outputId": "224a52ca-6a3c-4f81-f4eb-8e21f54ea48e"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-115-928cd9778d31>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for i in tqdm_notebook(range(50)):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfd15ac3a5174c2e86b52fe102e7ed6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#0 Test acc: 0.9342857003211975\n",
            "#1 Test acc: 0.9514285922050476\n",
            "#2 Test acc: 0.9342857003211975\n",
            "#3 Test acc: 0.9428571462631226\n",
            "#4 Test acc: 0.9399999976158142\n",
            "#5 Test acc: 0.9428571462631226\n",
            "#6 Test acc: 0.9371428489685059\n",
            "#7 Test acc: 0.9371428489685059\n",
            "#8 Test acc: 0.9628571271896362\n",
            "#9 Test acc: 0.9371428489685059\n",
            "#10 Test acc: 0.9371428489685059\n",
            "#11 Test acc: 0.9314285516738892\n",
            "#12 Test acc: 0.9514285922050476\n",
            "#13 Test acc: 0.9514285922050476\n",
            "#14 Test acc: 0.9457142949104309\n",
            "#15 Test acc: 0.9399999976158142\n",
            "#16 Test acc: 0.9342857003211975\n",
            "#17 Test acc: 0.9342857003211975\n",
            "#18 Test acc: 0.9342857003211975\n",
            "#19 Test acc: 0.9457142949104309\n",
            "#20 Test acc: 0.9371428489685059\n",
            "#21 Test acc: 0.9428571462631226\n",
            "#22 Test acc: 0.9599999785423279\n",
            "#23 Test acc: 0.9457142949104309\n",
            "#24 Test acc: 0.9514285922050476\n",
            "#25 Test acc: 0.9457142949104309\n",
            "#26 Test acc: 0.9571428298950195\n",
            "#27 Test acc: 0.9428571462631226\n",
            "#28 Test acc: 0.9371428489685059\n",
            "#29 Test acc: 0.9399999976158142\n",
            "#30 Test acc: 0.9571428298950195\n",
            "#31 Test acc: 0.9371428489685059\n",
            "#32 Test acc: 0.954285740852356\n",
            "#33 Test acc: 0.954285740852356\n",
            "#34 Test acc: 0.9342857003211975\n",
            "#35 Test acc: 0.9399999976158142\n",
            "#36 Test acc: 0.9485714435577393\n",
            "#37 Test acc: 0.9485714435577393\n",
            "#38 Test acc: 0.9285714030265808\n",
            "#39 Test acc: 0.9371428489685059\n",
            "#40 Test acc: 0.9485714435577393\n",
            "#41 Test acc: 0.9257143139839172\n",
            "#42 Test acc: 0.954285740852356\n",
            "#43 Test acc: 0.9257143139839172\n",
            "#44 Test acc: 0.9371428489685059\n",
            "#45 Test acc: 0.9399999976158142\n",
            "#46 Test acc: 0.9514285922050476\n",
            "#47 Test acc: 0.9485714435577393\n",
            "#48 Test acc: 0.9485714435577393\n",
            "#49 Test acc: 0.9399999976158142\n",
            "AVERAGE TEST ACCURACY :  0.943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gantrainacc = []\n",
        "gantrainloss = []\n",
        "ganvalacc = []\n",
        "ganvalloss = []\n",
        "for i in range (len(ganhistory)):\n",
        "    gantrainacc.append(ganhistory[i].history['accuracy'])\n",
        "    gantrainloss.append(ganhistory[i].history['loss'])\n",
        "    ganvalacc.append(ganhistory[i].history['val_accuracy'])\n",
        "    ganvalloss.append(ganhistory[i].history['val_loss'])\n",
        "\n",
        "gan_acc = np.mean(gantrainacc, axis=0)\n",
        "gan_val_acc = np.mean(ganvalacc, axis=0)\n",
        "gan_loss = np.mean(gantrainloss, axis=0)\n",
        "gan_val_loss = np.mean(ganvalloss, axis=0)\n",
        "epochs = range(1, len(gan_acc) + 1)\n",
        "plt.plot(epochs, gan_acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, gan_val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy for {}%'.format(fraction_of_data*100))\n",
        "plt.legend()\n",
        "plt.savefig(\"GANTrainAcc - {}%.png\".format(fraction_of_data*100))\n",
        "plt.figure()\n",
        "plt.plot(epochs, gan_loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, gan_val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss for {}%'.format(fraction_of_data*100))\n",
        "plt.legend()\n",
        "plt.savefig(\"GANTrainLoss - {}%.png\".format(fraction_of_data*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "TZBfE78OBmJc",
        "outputId": "0e051a92-dfa0-4aac-d991-de02e96571c3"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Real Training')\n",
        "plt.plot(epochs, val_acc, 'b', label='Real Validation')\n",
        "plt.plot(epochs, gan_acc, 'ro', label='Real+GAN Training')\n",
        "plt.plot(epochs, gan_val_acc, 'r', label='Real+GAN Validation')\n",
        "plt.title('Training and validation accuracy for {}%'.format(fraction_of_data*100))\n",
        "plt.legend()\n",
        "plt.savefig(\"GANREALAcc - {}%.png\".format(fraction_of_data*100))\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Real Training')\n",
        "plt.plot(epochs, val_loss, 'b', label='Real Validation')\n",
        "plt.plot(epochs, gan_loss, 'ro', label='Real+GAN Training')\n",
        "plt.plot(epochs, gan_val_loss, 'r', label='Real+GAN Validation')\n",
        "plt.title('Training and validation loss for {}%'.format(fraction_of_data*100))\n",
        "plt.legend()\n",
        "plt.savefig(\"GANREALLoss - {}%.png\".format(fraction_of_data*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "F-sZFNZgDYFm",
        "outputId": "3844608b-6e36-465a-ede4-303dc96c5675"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-795773bef58a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Real Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Real Validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Real+GAN Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_val_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Real+GAN Validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and validation accuracy for {}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfraction_of_data\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ]
}